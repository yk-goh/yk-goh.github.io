---
layout: single
title: "Retrieving CounterFactual; with restrictions"
categories: XAI
sidebar: true
use_math: true
---

# bank 데이터를 사용하여 CFRL 구하기
> immutable_features, ranges and C(condition)

## 0. import libraries and data


```python
# !pip install xgboost
```


```python
# !pip install alibi
```


```python
import os
import numpy as np
import pandas as pd
from copy import deepcopy
from typing import List, Tuple, Dict, Callable
import tensorflow as tf
import tensorflow.keras as keras
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from alibi.explainers import CounterfactualRLTabular, CounterfactualRL
from alibi.datasets import fetch_adult
from alibi.explainers.backends.cfrl_tabular import get_he_preprocessor, apply_category_mapping

np.set_printoptions(precision=3, suppress=True)
```


```python
from google.colab import files

uploaded = files.upload()  # Opens a dialogue to select the file from your local system
```






```python
df = pd.read_csv('bank.csv', sep=';')
```

## 1. 데이터 확인
bank 데이터셋은 은행의 마케팅캠페인 정보와 고객이 해당 캠페인 결과 은행의 정기예금 상품에 가입했는지를 기록한 데이터셋이다. 16개의 특성변수가 있으며 목적변수는 y이다. 


```python
df.head()
```




 <div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>balance</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>day</th>
      <th>month</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>poutcome</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>30</td>
      <td>unemployed</td>
      <td>married</td>
      <td>primary</td>
      <td>no</td>
      <td>1787</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>19</td>
      <td>oct</td>
      <td>79</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>33</td>
      <td>services</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>4789</td>
      <td>yes</td>
      <td>yes</td>
      <td>cellular</td>
      <td>11</td>
      <td>may</td>
      <td>220</td>
      <td>1</td>
      <td>339</td>
      <td>4</td>
      <td>failure</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
      <td>management</td>
      <td>single</td>
      <td>tertiary</td>
      <td>no</td>
      <td>1350</td>
      <td>yes</td>
      <td>no</td>
      <td>cellular</td>
      <td>16</td>
      <td>apr</td>
      <td>185</td>
      <td>1</td>
      <td>330</td>
      <td>1</td>
      <td>failure</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30</td>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>1476</td>
      <td>yes</td>
      <td>yes</td>
      <td>unknown</td>
      <td>3</td>
      <td>jun</td>
      <td>199</td>
      <td>4</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>blue-collar</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>0</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>5</td>
      <td>may</td>
      <td>226</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>
   




지난주와 마찬가지로 목적변수의 분포가 약 8:1로 ‘no’가 더 많은 불균형 데이터임을 확인하고,


```python
df['y'].value_counts()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
    <tr>
      <th>y</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>no</th>
      <td>4000</td>
    </tr>
    <tr>
      <th>yes</th>
      <td>521</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>



범주형 특성변수와 실수형 특성변수가 무엇인지 파악한다. df.describe(include=’all’)을 실행하면 범주형 변수에 대해서는 범주값의 개수(unique)와 각 범주에서 가장 빈도가 높은 범주값과 그 빈도를 보여주고 실수형 변수에 대해서는 요약통계량을 출력한다. 특성변수 중 age(연령), balance(잔고), day(날짜), duration(최근 연락의 통화시간(초 단위)), campaign(이 캠페인으로 연락한 횟수), pdays(지난 캠페인 연락으로부터 경과일 수), previous(이 캠페인 이전에 연락한 횟수)는 실수형 특성변수이다.


```python
df.describe(include='all')
```






<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>balance</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>day</th>
      <th>month</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>poutcome</th>
      <th>y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>4521.000000</td>
      <td>4521</td>
      <td>4521</td>
      <td>4521</td>
      <td>4521</td>
      <td>4521.000000</td>
      <td>4521</td>
      <td>4521</td>
      <td>4521</td>
      <td>4521.000000</td>
      <td>4521</td>
      <td>4521.000000</td>
      <td>4521.000000</td>
      <td>4521.000000</td>
      <td>4521.000000</td>
      <td>4521</td>
      <td>4521</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>NaN</td>
      <td>12</td>
      <td>3</td>
      <td>4</td>
      <td>2</td>
      <td>NaN</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>NaN</td>
      <td>12</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>top</th>
      <td>NaN</td>
      <td>management</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>NaN</td>
      <td>yes</td>
      <td>no</td>
      <td>cellular</td>
      <td>NaN</td>
      <td>may</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>unknown</td>
      <td>no</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>NaN</td>
      <td>969</td>
      <td>2797</td>
      <td>2306</td>
      <td>4445</td>
      <td>NaN</td>
      <td>2559</td>
      <td>3830</td>
      <td>2896</td>
      <td>NaN</td>
      <td>1398</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3705</td>
      <td>4000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>41.170095</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1422.657819</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>15.915284</td>
      <td>NaN</td>
      <td>263.961292</td>
      <td>2.793630</td>
      <td>39.766645</td>
      <td>0.542579</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>std</th>
      <td>10.576211</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3009.638142</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>8.247667</td>
      <td>NaN</td>
      <td>259.856633</td>
      <td>3.109807</td>
      <td>100.121124</td>
      <td>1.693562</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>min</th>
      <td>19.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-3313.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.000000</td>
      <td>NaN</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>33.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>69.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.000000</td>
      <td>NaN</td>
      <td>104.000000</td>
      <td>1.000000</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>39.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>444.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>16.000000</td>
      <td>NaN</td>
      <td>185.000000</td>
      <td>2.000000</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>49.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1480.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>21.000000</td>
      <td>NaN</td>
      <td>329.000000</td>
      <td>3.000000</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>max</th>
      <td>87.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>71188.000000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>31.000000</td>
      <td>NaN</td>
      <td>3025.000000</td>
      <td>50.000000</td>
      <td>871.000000</td>
      <td>25.000000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

## 2. 전처리

### 2.1 day 변수 범주화


```python
def get_day_cat(day):
  if day <= 10:
    day_cat = 'early'
  elif day <= 20:
    day_cat = 'mid'
  else:
    day_cat = 'late'
  return day_cat

df['day_cat'] = df['day'].apply(get_day_cat)
df.head()
```






<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>balance</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>day</th>
      <th>month</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>poutcome</th>
      <th>y</th>
      <th>day_cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>30</td>
      <td>unemployed</td>
      <td>married</td>
      <td>primary</td>
      <td>no</td>
      <td>1787</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>19</td>
      <td>oct</td>
      <td>79</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
      <td>mid</td>
    </tr>
    <tr>
      <th>1</th>
      <td>33</td>
      <td>services</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>4789</td>
      <td>yes</td>
      <td>yes</td>
      <td>cellular</td>
      <td>11</td>
      <td>may</td>
      <td>220</td>
      <td>1</td>
      <td>339</td>
      <td>4</td>
      <td>failure</td>
      <td>no</td>
      <td>mid</td>
    </tr>
    <tr>
      <th>2</th>
      <td>35</td>
      <td>management</td>
      <td>single</td>
      <td>tertiary</td>
      <td>no</td>
      <td>1350</td>
      <td>yes</td>
      <td>no</td>
      <td>cellular</td>
      <td>16</td>
      <td>apr</td>
      <td>185</td>
      <td>1</td>
      <td>330</td>
      <td>1</td>
      <td>failure</td>
      <td>no</td>
      <td>mid</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30</td>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>1476</td>
      <td>yes</td>
      <td>yes</td>
      <td>unknown</td>
      <td>3</td>
      <td>jun</td>
      <td>199</td>
      <td>4</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
      <td>early</td>
    </tr>
    <tr>
      <th>4</th>
      <td>59</td>
      <td>blue-collar</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>0</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>5</td>
      <td>may</td>
      <td>226</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
      <td>unknown</td>
      <td>no</td>
      <td>early</td>
    </tr>
  </tbody>
</table>
</div>




### 2.2 특성변수의 순서 변경
전처리 과정의 용이성을 위해 범주형 특성변수끼리, 실수형 특성변수끼리 모이도록 순서를 변경한다. 범주형 특성변수 열 개가 앞부분에, 실수형 특성변수 여섯 개는 뒷부분에 위치하도록 한다. 


```python
df_cat = df[['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'day_cat']]
df_num = df[['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']]
df_X = pd.concat([df_cat, df_num], axis=1)
df_target = df[['y']]
```

### 2.3 category map 생성
모든 특성변수명을 담은 리스트와 범주형 특성변수의 이름과 인덱스를 담은 리스트, 실수형 특성변수의 이름과 인덱스를 담은 리스트를 각각 생성한다. 범주형 특성변수 인덱스 리스트를 alibi.utils 라이브러리가 제공하는 gen_category_map 함수에 넘겨 category map을 생성한다. category map은 추후 4.에서 Heterogeneous preprocessor를 생성할 때 필요하다. 


```python
from alibi.utils import gen_category_map

feature_names = list(df_X.columns)
categorical_ids = list(range(10))
category_map = gen_category_map(data = df_X.to_numpy(), categorical_columns = categorical_ids)
category_map
```




    {0: ['admin.',
      'blue-collar',
      'entrepreneur',
      'housemaid',
      'management',
      'retired',
      'self-employed',
      'services',
      'student',
      'technician',
      'unemployed',
      'unknown'],
     1: ['divorced', 'married', 'single'],
     2: ['primary', 'secondary', 'tertiary', 'unknown'],
     3: ['no', 'yes'],
     4: ['no', 'yes'],
     5: ['no', 'yes'],
     6: ['cellular', 'telephone', 'unknown'],
     7: ['apr',
      'aug',
      'dec',
      'feb',
      'jan',
      'jul',
      'jun',
      'mar',
      'may',
      'nov',
      'oct',
      'sep'],
     8: ['failure', 'other', 'success', 'unknown'],
     9: ['early', 'late', 'mid']}




```python
categorical_names = [feature_names[i] for i in category_map.keys()]
categorical_names
```




    ['job',
     'marital',
     'education',
     'default',
     'housing',
     'loan',
     'contact',
     'month',
     'poutcome',
     'day_cat']



위 프로그램에서 생성한 categorical_names를 출력하면 ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', month', 'poutcome', 'day_cat']이 출력되어 제대로 생성되었음을 확인할 수 있다.


```python
numerical_names = list(set(feature_names) - set(categorical_names))
# numerical_names = [name for i, name in enumerate(feature_names) if i not in category_map.keys()]
numerical_names
```




    ['campaign', 'balance', 'pdays', 'duration', 'previous', 'age']




```python
numerical_ids = [i for i in range(len(feature_names)) if i not in category_map.keys()]
numerical_ids
```




    [10, 11, 12, 13, 14, 15]



### 2.4 ordinal encoding
범주형 특성변수의 변수값이 범주가 아닌 숫자가 되도록, 순서형 정수로 인코딩한다.


```python
oe = OrdinalEncoder()
df_X[categorical_names] = oe.fit_transform(df_X[categorical_names])
df_X.head()
```



<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>30</td>
      <td>1787</td>
      <td>79</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>33</td>
      <td>4789</td>
      <td>220</td>
      <td>1</td>
      <td>339</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>35</td>
      <td>1350</td>
      <td>185</td>
      <td>1</td>
      <td>330</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>30</td>
      <td>1476</td>
      <td>199</td>
      <td>4</td>
      <td>-1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>59</td>
      <td>0</td>
      <td>226</td>
      <td>1</td>
      <td>-1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>





### 2.5 학습데이터와 시험데이터 분할
목적변수 역시 0과 1로 맵핑한다. 데이터를 alibi로 다루어야 하므로 alibi 라이브러리가 취급하는 numpy로 형변환 후 학습데이터와 시험데이터로 분할한다. 


```python
df_target = df_target["y"].map({'no': 0,'yes': 1})
X, y = df_X.to_numpy(), df_target.to_numpy()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train[:3])
print(y[:3])
```

    [[   2.    0.    2.    0.    0.    0.    0.    9.    3.    2.   34.  262.
       371.    1.   -1.    0.]
     [   4.    1.    2.    0.    0.    0.    0.    1.    3.    2.   32. 2349.
       134.    5.   -1.    0.]
     [   9.    2.    1.    0.    0.    0.    0.    1.    3.    0.   34. 1076.
        70.    2.   -1.    0.]]
    [0 0 0]


### 2.6 Column Transformer 적용
실수형 변수의 표준화와 범주형 변수의 one-hot 인코딩을 한번에 처리하기 위해 ColumnTransformer를 사용한다. X 데이터를 Column Transformer에 통과시켜(transform) X_train_ohe를 생성한다. 이는 분류모형을 적합시킬 때 사용될 것이다. 


```python
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_ids),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_ids)
    ])
```


```python
preprocessor.fit(X_train)

X_train_ohe = preprocessor.transform(X_train)
X_test_ohe = preprocessor.transform(X_test)
```

## 3. 블랙박스 분류모형 생성
CounterfactualRL은 미분가능한 glass box 모형은 물론 미분불가능한 블랙박스 모형에도 적용할 수 있다. 이 과제에서는 미분이 불가능한 블랙박스 모형인 Random Forest 모형으로 이항분류문제를 학습시키기로 한다. 


```python
clf = RandomForestClassifier(max_depth=5, min_samples_split=10, random_state=42)
clf.fit(X_train_ohe, y_train) # ravel(): flattens y_train... from shape (3616,1) to shape (3616,)
```







분류모형이 블랙박스이므로 CFRL 동기화 시 모형 대신 예측함수를 파라미터로 넘겨주어야 한다. 다음과 같이 예측함수를 미리 정의해 둔다. 


```python
# 블랙박스 모형이므로 예측함수를 정의해서 나중에 인자로 넘겨준다
predictor = lambda x: clf.predict_proba(preprocessor.transform(x))

# 모형의 accuracy를 구하면 이렇다.
acc = accuracy_score(y_true=y_test, y_pred=predictor(X_test).argmax(axis=1))
print(f'Accuracy: {acc}')
f1 = f1_score(y_true=y_test, y_pred=predictor(X_test).argmax(axis=1))
print(f'F1 score: {f1}')
```

    Accuracy: 0.8983425414364641
    F1 score: 0.1320754716981132


## AutoEncoder 정의
### 4.1 encoder
Encoder 클래스는 keras 모듈의 Model 클래스를 상속받는다. __init__은 생성자(Constructor)를 정의하는데, 인자로 hidden_dim과 latent_dim이 주어지면 그 숫자를 각각 노드 수로 하는 Fully connected(Dense) 층을 만든다. 한편 call을 정의하면 Encoder 클래스의 인스턴스는 함수처럼 호출될 수 있으며, 인자로 들어가는 x는 fc1층과 relu 활성함수, fc2층과 tanh 활성함수를 차례로 통과하게 된다. 


```python
class Encoder(keras.Model):
  # Constructor
  def __init__(self, hidden_dim, latent_dim, **kwargs):
    super().__init__(**kwargs)
    self.fc1 = keras.layers.Dense(hidden_dim)
    self.fc2 = keras.layers.Dense(latent_dim)

  # callable . call을 정의하면 이 클래스의 인스턴스는 함수처럼 호출될 수 있다.
  def call(self, x:tf.Tensor, **kwargs) -> tf.Tensor:
    x = self.fc1(x)
    x = tf.nn.relu(x)
    x = self.fc2(x)
    x = tf.nn.tanh(x)
    return x
```

### 4.2 decoder
Decoder 클래스 역시 keras Model 클래스의 자식 클래스이다. CFRL에서 사용되는 decoder의 특징은 다중 출력층(Multiple outputs)이다. 첫번째 출력층은 실수형 특성변수를 출력한다(총 6개 노드). 두번째 이후 출력층은 범주형 특성변수의 출력이다. 각 출력층에는 범주형 특성변수의 범주 수만큼 노드가 있다. 


```python
class Decoder(keras.Model):
  def __init__(self, hidden_dim, output_dims, **kwargs):
    super().__init__(**kwargs)
    self.fc1 = keras.layers.Dense(hidden_dim)
    self.fcs = [keras.layers.Dense(dim) for dim in output_dims]
  def call(self, x:tf.Tensor, **kwargs) -> tf.Tensor:
    x = self.fc1(x)
    x = tf.nn.relu(x)
    xs = [fc(x) for fc in self.fcs]
    return xs

```

### 4.3 Encoder와 Decoder 연결: HeAutoEncoder
HeAutoEncoder 클래스는 encoder와 decoder를 입력받으면서 동기화 된다. encoder의 출력(z)이 decoder의 입력으로 들어감을 확인할 수 있다. 



```python
class HeAutoEncoder(keras.Model):
  def __init__(self, encoder:keras.Model, decoder:keras.Model, **kwargs):
    super().__init__(**kwargs)
    self.encoder = encoder
    self.decoder = decoder
  def call(self, x: tf.Tensor, **kwargs):
    z = self.encoder(x)
    x_hat = self.decoder(z)
    return x_hat
```

## 4.4 auto encoder의 입력데이터와 출력데이터 정의

get_he_preprocessor() 함수는 `data preprocessor`와 `inverse data preprocessor`를 반환한다.

- `data preprocessor` (heae_preprocessor)

Tabular 데이터에는 실수형과 범주형이라는, 이질적인(heterogeneous) 데이터 타입이 혼재되어 있다.
alibi 라이브러리의 get_he_preprocessor() 함수는 실수형 특성변수는 표준화 하고 범주형 특성변수는 one-hot 인코딩 함으로써 counterfactual 생성 시 모든 변수가 일관적으로 다뤄질 수 있도록 한다.

- `inverse data preprocessor` (heae_inv_preprocessor)

강화학습 모형에서 encoder출력 형태로 출력되는 특성변수를 원래의 특성변수 형식으로 환원한다. `inv_preprocessor(preprocessor(x)) = x`
생성된 counterfactual은 모형이 학습한 입력데이터 형태와 동일한 형태로 출력되어야 한다. counterfactual이 모형이 이해할 수 있는 형태로 출력되어야 해석이 가능하기 때문이다.

### 4.4 HeAutoEncoder의 입력데이터와 출력데이터 정의
alibi 라이브러리가 제공하는 get_he_preprocessor() 함수는 data preprocessor와 inverse data preprocessor를 반환한다. 여기서 he는 heterogeneous(이질적인)를 의미한다. Tabular 데이터에는 실수형과 범주형이라는, 이질적인 데이터 타입이 혼재되어 있다. 
- get_he_preprocessor()의 반환 중 data processor는 실수형 특성변수를 표준화 하고 범주형 특성변수는 one-hot 인코딩 함으로써 counterfactual 생성 시 모든 변수가 일관적으로 다뤄질 수 있도록 한다. 
- 한편 inverse data preprocessor는 강화학습 모형에서 encoder출력 형태로 출력되는 특성변수를 원래의 특성변수 형식으로 환원한다. 즉 heae_inv_preprocessor(heae_preprocessor(x)) = x이다. counterfactual은 모형이 이해할 수 있는 형태로 출력되어야(즉, 모형이 학습한 입력데이터 형태와 동일한 형태로 출력되어야) 해석이 가능하다. 이를 가능케 하는 것이 inverse data preprocessor이다. 



```python
# Define attribute types, required for datatype conversion.
feature_types = {"Age": int, "Balance": int, "Duration": int, "Campaign": int, "PDays": int, "Previous": int}

heae_preprocessor, heae_inv_preprocessor = get_he_preprocessor(X=X_train,
                                                               feature_names=feature_names,
                                                               category_map = category_map,
                                                               feature_types=feature_types)
```

한편 HeAutoEncoder에도 fit 단계가 필요하며 학습데이터 X, y를 fit 메서드에 넘겨야 한다. 이때 fit의 X 인자에는 기 생성한 X_train을 heae_preprocessor에 통과시켜 전처리한 trainset_input을 넘겨준다. 한편 fit의 y 인자에는 HeAutoEncoder의 출력이 다중 출력이므로 dictionary 타입의 trainset_output을 넘겨준다. 실수형 특성변수에 해당하는 key는 “output_1”이고 범주형 특성변수에 해당하는 key는 “output_2”부터 “output_11”이다. 

trainset_input과 trainset_output을 튜플로 묶은 후 from_tensor_slices를 적용하면 첫번째 축으로 잘라서 trainset_input과 trainset_output을 짝지어 가져온다. 잘 섞은 후(shuffle) 32배치 단위로 표본을 추출한다. 


```python
# Define trainset
# input
trainset_input = heae_preprocessor(X_train).astype(np.float32)
print(trainset_input.shape)

# output
trainset_output = {"output_1": trainset_input[:, :len(numerical_ids)]} #initialize with numeric variables in 1st output layer
for i, cat_id in enumerate(categorical_ids):
  trainset_output.update({f"output_{i+2}": X_train[:, cat_id]})

# trainset
trainset = tf.data.Dataset.from_tensor_slices((trainset_input, trainset_output))  # tuple
trainset = trainset.shuffle(128).batch(32, drop_remainder=True)
```

    (3616, 53)


다음으로 파라미터 값을 지정한다.
- `HIDDEN_DIM`: encoder와 decoder의 은닉층 수를 뜻한다.
- `LATENT_DIM`: encoder의 출력노드 수
- `OUTPUT_DIMS`: 다중출력인 decoder의 각 출력층의 출력노드 수  
    - `OUTPUT_DIMS`를 출력하여 확인하면 실수형 특성변수의 출력노드 수는 6개, 첫번째 특성변수(job)의 범주값이 12개이므로 출력노드 또한 12개, ...임을 알 수 있다. 


```python
EPOCHS = 50
HIDDEN_DIM = 64
LATENT_DIM = 15

OUTPUT_DIMS = [len(numerical_ids)]
OUTPUT_DIMS += [len(category_map[i]) for i in categorical_ids]

print(OUTPUT_DIMS)
```

    [6, 12, 3, 4, 2, 2, 2, 3, 12, 4, 3]


### 4.5 HeAutoEncoder 학습
HeAutoEncoder의 학습을 위해 손실함수와 가중치를 정의한다. 실수형 목적변수의 손실함수는 MSE를, 범주형 목적변수의 손실함수는 SparseCategoricalCrossentropy를 부여한다. 범주형 목적변수가 순서형 정수로 맵핑되었기 때문이다. SparseCategoricalCrossentropy 손실의 경우, HeAutoEncoder 모형의 마지막 레이어에서 소프트맥스를 사용하지 않았기 때문에 from_logits=True로 하여 모델의 마지막 출력인 logit값을 가지고 손실함수가 내부적으로 소프트맥스를 처리하도록 한다. 손실함수의 가중치는 실수형은 1, 범주형에는 각각 1/10(10은 범주형 특성변수의 개수이다)을 준다. 

(참고)
- from_logits=True를 사용할 경우, 모델의 마지막 레이어에서 소프트맥스를 직접 적용하지 않아야 한다. 모델의 마지막 출력이 로짓이어야 하며, 소프트맥스를 내부적으로 손실 함수에서 처리한다.
- from_logits=False를 사용할 경우, 모델의 마지막 레이어에서 소프트맥스를 직접 적용하여 출력값을 확률로 변환한 상태여야 한다.


```python
# HE 오토인코더 생성
heae = HeAutoEncoder(encoder = Encoder(hidden_dim = HIDDEN_DIM, latent_dim = LATENT_DIM),
                     decoder = Decoder(hidden_dim = HIDDEN_DIM, output_dims = OUTPUT_DIMS)
                     )

# 손실함수와 가중치: 일단 실수형 목적변수의 손실함수와 가중치로 초기화
he_loss = [keras.losses.MeanSquaredError()]
he_loss_weights = [1.]

# 범주형 목적변수의 손실함수 및 가중치를 붙인다(append)
for i in range(len(categorical_ids)):
  he_loss.append(keras.losses.SparseCategoricalCrossentropy(from_logits=True))
  he_loss_weights.append(1./len(categorical_ids))

# metrics
metrics = {}
for i, cat_name in enumerate(categorical_names):
  metrics.update({f"output_{i+2}": keras.metrics.SparseCategoricalAccuracy()})

# complie and fit
heae.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001),
             loss = he_loss,
             loss_weights = he_loss_weights,
             metrics = metrics)
heae.fit(trainset, epochs = EPOCHS)
```

    Epoch 1/50
    113/113 [==============================] - 4s 3ms/step - loss: 1.5737 - output_1_loss: 0.5448 - output_2_loss: 2.1832 - output_3_loss: 0.8757 - output_4_loss: 1.1217 - output_5_loss: 0.2658 - output_6_loss: 0.5912 - output_7_loss: 0.4413 - output_8_loss: 0.8606 - output_9_loss: 2.1493 - output_10_loss: 0.7867 - output_11_loss: 1.0138 - output_2_sparse_categorical_accuracy: 0.2154 - output_3_sparse_categorical_accuracy: 0.5835 - output_4_sparse_categorical_accuracy: 0.5094 - output_5_sparse_categorical_accuracy: 0.9187 - output_6_sparse_categorical_accuracy: 0.7171 - output_7_sparse_categorical_accuracy: 0.8382 - output_8_sparse_categorical_accuracy: 0.6347 - output_9_sparse_categorical_accuracy: 0.2652 - output_10_sparse_categorical_accuracy: 0.7367 - output_11_sparse_categorical_accuracy: 0.4726
    ....
    Epoch 50/50
    113/113 [==============================] - 0s 3ms/step - loss: 0.0859 - output_1_loss: 0.0158 - output_2_loss: 0.1920 - output_3_loss: 0.0305 - output_4_loss: 0.0975 - output_5_loss: 0.0087 - output_6_loss: 0.0177 - output_7_loss: 0.0197 - output_8_loss: 0.0402 - output_9_loss: 0.1780 - output_10_loss: 0.0750 - output_11_loss: 0.0415 - output_2_sparse_categorical_accuracy: 0.9463 - output_3_sparse_categorical_accuracy: 0.9967 - output_4_sparse_categorical_accuracy: 0.9679 - output_5_sparse_categorical_accuracy: 0.9975 - output_6_sparse_categorical_accuracy: 0.9947 - output_7_sparse_categorical_accuracy: 0.9956 - output_8_sparse_categorical_accuracy: 0.9892 - output_9_sparse_categorical_accuracy: 0.9499 - output_10_sparse_categorical_accuracy: 0.9712 - output_11_sparse_categorical_accuracy: 0.9876





## 5. CFRL 동기화

`COEF_SPARSITY`는 $\theta_1$ 즉 $L_1(\delta)$의 가중치이다. $\delta$를 최소로 하여 cf가 원래 특성변수값에 근접하도록 한다.

`COEF_CONSISTENCY`는 $\theta_2$ 즉 $L_2(x+\delta, AE(x+\delta))$의 가중치이다. 이는 cf가 학습데이터와 분포적으로 동일하도록 규제한다.


```python
COEFF_SPARSITY=0.5
COEFF_CONSISTENCY=0.5
TRAIN_STEPS=10000
BATCH_SIZE=100
```

`immutable_features`: cf 생성 시 변하지 않아야 할 특성변수를 지정한다.
- 고객의 개인특성(직업, 혼인상태, 학력, 신용불량여부)과 과거 마케팅캠페인에 관한 데이터는 변동할 수 없다.

`ranges`: Age는 증가만 가능하도록 허용한다. education 변수도 증가만 가능해야 하지만 CounterfactualRLTabular 클래스의 인스턴스화에 사용되는 ranges 파라미터는 실수형 변수에 대해서만 증감을 제한한다.
- 고객의 연령(age)과 이번 마케팅캠페인의 고객접촉횟수(campaign)는 증가만 할 수 있다.


```python
"""
CATEGORICAL: job	marital	education	default	housing	loan	contact	month	poutcome	day_cat
NUMERIC: age	balance	duration	campaign	pdays	previous
"""
immutable_features = ['job', 'marital', 'education', 'default', 'previous', 'poutcome'] # 혼인상태, 학력, 신용불량여부, 이전 캠페인에서 접촉 횟수, 이전 캠페인의 결과
ranges = {'age': [0, 1],
          'campaign': [0,1] # 현재 캠페인에서 고객과 접촉한 횟수
          }
```

CFRL을 동기화 하고, 강화학습 모형을 학습시켜야 하므로 .fit() 을 실행한다.


```python
explainer = CounterfactualRLTabular(predictor = predictor,
                                    encoder = heae.encoder,
                                    decoder = heae.decoder,
                                    latent_dim = LATENT_DIM,
                                    encoder_preprocessor = heae_preprocessor,
                                    decoder_inv_preprocessor = heae_inv_preprocessor,
                                    coeff_sparsity = COEFF_SPARSITY,
                                    coeff_consistency = COEFF_CONSISTENCY,
                                    category_map = category_map,
                                    feature_names = feature_names,
                                    ranges = ranges,
                                    immutable_features = immutable_features,
                                    train_steps = TRAIN_STEPS,
                                    batch_size = BATCH_SIZE)

explainer = explainer.fit(X=X_train)
```

    100%|██████████| 10000/10000 [10:35<00:00, 15.73it/s]


## 6. CFRL 구하기

CFRL은 2개 이상의 표본에 대하여 cf를 생성할 수 있다.

X_test의 예측 레이블이 0인 표본(즉, 정기예금 상품에 가입하지 않을 것으로 예측되는 표본)을 X_negative로 정의하고 이중 100개를 선택하여 예측 레이블이 1이 되는 CFRL을 구하자. `Y_t = np.array([1])`
- age는 0~10세 증가할 수 있게 한다
- campaign은 0~2만큼만 증가할 수 있게 한다. 은행이 고객에게 연락을 너무 많이 하면 또다른 CS 이슈가 발생할 수 있으니까.


```python
X_negative = X_test[np.argmax(predictor(X_test), axis=1) == 0]
X = X_negative[:100]
# target label: 1
Y_t = np.array([1])
C = [{'age': [0, 10], 'campaign': [0, 2]}]

explanation = explainer.explain(X, Y_t, C)
```

    100%|██████████| 1/1 [00:00<00:00, 23.76it/s]


다음 프로그램은 apply_category_mapping을 통해 순서형 정수를 범주값으로 바꾸고, 원표본 100개와 cf 100개를 각각 데이터프레임으로 만든다.


```python
orig = np.concatenate([explanation.data['orig']['X'], explanation.data['orig']['class']], axis=1)

cf = np.concatenate([explanation.data['cf']['X'], explanation.data['cf']['class']], axis=1)

# category map 업데이트 하기(목적변수 추가)
feature_names = feature_names + ['Label']
target_names = ['no', 'yes']
category_map = deepcopy(category_map) # deepcopy: 새로운 메모리 주소에 인스턴스 생성
category_map.update({feature_names.index("Label"): target_names})

# 순서형 정수로 인코딩된 범주값을 문자열로 바꾸기
orig_pd = pd.DataFrame(apply_category_mapping(orig, category_map), columns=feature_names)
cf_pd = pd.DataFrame(apply_category_mapping(cf, category_map), columns=feature_names)
```

    /usr/local/lib/python3.10/dist-packages/alibi/explainers/backends/cfrl_tabular.py:877: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
    The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
    
    For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
    
    
      pd_X[key].replace(range(len(category_map[key])), category_map[key], inplace=True)



```python
orig_pd.head(5)
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>entrepreneur</td>
      <td>married</td>
      <td>secondary</td>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>cellular</td>
      <td>jul</td>
      <td>unknown</td>
      <td>late</td>
      <td>51.0</td>
      <td>-2082.0</td>
      <td>123.0</td>
      <td>6.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>other</td>
      <td>early</td>
      <td>50.0</td>
      <td>2881.0</td>
      <td>510.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>technician</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>unknown</td>
      <td>early</td>
      <td>50.0</td>
      <td>1412.0</td>
      <td>131.0</td>
      <td>3.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>jun</td>
      <td>unknown</td>
      <td>early</td>
      <td>37.0</td>
      <td>0.0</td>
      <td>247.0</td>
      <td>13.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>admin.</td>
      <td>single</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.0</td>
      <td>757.0</td>
      <td>343.0</td>
      <td>2.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>





```python
cf_pd.head(5)
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>entrepreneur</td>
      <td>married</td>
      <td>secondary</td>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>cellular</td>
      <td>jul</td>
      <td>unknown</td>
      <td>mid</td>
      <td>51.171792</td>
      <td>-1746.000141</td>
      <td>177.970766</td>
      <td>6.0</td>
      <td>7.759286</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>other</td>
      <td>early</td>
      <td>50.108274</td>
      <td>2099.090321</td>
      <td>513.311777</td>
      <td>2.276312</td>
      <td>22.545976</td>
      <td>5.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>technician</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>unknown</td>
      <td>early</td>
      <td>50.053603</td>
      <td>1324.822779</td>
      <td>130.641457</td>
      <td>3.286392</td>
      <td>4.611033</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>jun</td>
      <td>unknown</td>
      <td>early</td>
      <td>37.0</td>
      <td>169.334007</td>
      <td>239.063277</td>
      <td>13.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>admin.</td>
      <td>single</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.0</td>
      <td>907.22132</td>
      <td>343.816504</td>
      <td>2.239352</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>





제한조건이 많아서인지, 레이블 NO로 예측된 100개 표본 중 단 2개에 대해서만 counterfactual을 구할 수 있었다.


```python
cf_pd['Label'].value_counts()
```




<div>

</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
    <tr>
      <th>Label</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>no</th>
      <td>98</td>
    </tr>
    <tr>
      <th>yes</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>



## 7. 조건을 완화하여 CFRL 다시 동기화

theta_1, theta_2를 각각 0.1로 낮추어 규제화 정도를 약화하였다. 원본 특성변수값 혹은 학습데이터의 분포와 좀더 다른 counterfactual도 생성될 수 있도록 하기 위함이다. 직업은 unemployed, student, retired, unknown 중 하나의 직업군으로 변하도록 제한조건을 부여하였다(이전 실행에서는 직업을 고정하였다). 또한 연령은 0~20세까지 증가할 수 있도록 하였고 고객 컨택 횟수는 0~3회까지 증가할 수 있도록 제한조건을 약간 완화하였다.


```python
COEFF_SPARSITY=0.1
COEFF_CONSISTENCY=0.1
TRAIN_STEPS=10000
BATCH_SIZE=100

"""
CATEGORICAL: job	marital	education	default	housing	loan	contact	month	poutcome	day_cat
NUMERIC: age	balance	duration	campaign	pdays	previous
"""
immutable_features = ['marital', 'education', 'default', 'previous', 'poutcome'] # 혼인상태, 학력, 신용불량여부, 이전 캠페인에서 접촉 횟수, 이전 캠페인의 결과
ranges = {'age': [0, 1],
          'campaign': [0,1], # 현재 캠페인에서 고객과 접촉한 횟수
          'job': ['unemployed', 'student', 'retired', 'unknown']
          }

explainer = CounterfactualRLTabular(predictor = predictor,
                                    encoder = heae.encoder,
                                    decoder = heae.decoder,
                                    latent_dim = LATENT_DIM,
                                    encoder_preprocessor = heae_preprocessor,
                                    decoder_inv_preprocessor = heae_inv_preprocessor,
                                    coeff_sparsity = COEFF_SPARSITY,
                                    coeff_consistency = COEFF_CONSISTENCY,
                                    category_map = category_map,
                                    feature_names = feature_names,
                                    ranges = ranges,
                                    immutable_features = immutable_features,
                                    train_steps = TRAIN_STEPS,
                                    batch_size = BATCH_SIZE)

explainer = explainer.fit(X=X_train)
```

    100%|██████████| 10000/10000 [10:37<00:00, 15.69it/s]



```python
X_negative = X_test[np.argmax(predictor(X_test), axis=1) == 0]
X = X_negative[:100]
# target label: 1
Y_t = np.array([1])
C = [{'age': [0, 20], 'campaign': [0, 3]}]

explanation = explainer.explain(X, Y_t, C)
```

    100%|██████████| 1/1 [00:00<00:00, 28.59it/s]



```python
orig = np.concatenate([explanation.data['orig']['X'], explanation.data['orig']['class']], axis=1)

cf = np.concatenate([explanation.data['cf']['X'], explanation.data['cf']['class']], axis=1)

# category map 업데이트 하기(목적변수 추가)
feature_names = feature_names + ['Label']
target_names = ['no', 'yes']
category_map = deepcopy(category_map) # deepcopy: 새로운 메모리 주소에 인스턴스 생성
category_map.update({feature_names.index("Label"): target_names})

# 순서형 정수로 인코딩된 범주값을 문자열로 바꾸기
orig_pd = pd.DataFrame(apply_category_mapping(orig, category_map), columns=feature_names)
cf_pd = pd.DataFrame(apply_category_mapping(cf, category_map), columns=feature_names)
```

    /usr/local/lib/python3.10/dist-packages/alibi/explainers/backends/cfrl_tabular.py:877: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
    The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
    
    For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
    
    
      pd_X[key].replace(range(len(category_map[key])), category_map[key], inplace=True)



```python
orig_pd.head(10)
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>entrepreneur</td>
      <td>married</td>
      <td>secondary</td>
      <td>yes</td>
      <td>no</td>
      <td>yes</td>
      <td>cellular</td>
      <td>jul</td>
      <td>unknown</td>
      <td>late</td>
      <td>51.0</td>
      <td>-2082.0</td>
      <td>123.0</td>
      <td>6.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>other</td>
      <td>early</td>
      <td>50.0</td>
      <td>2881.0</td>
      <td>510.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>technician</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>unknown</td>
      <td>early</td>
      <td>50.0</td>
      <td>1412.0</td>
      <td>131.0</td>
      <td>3.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>jun</td>
      <td>unknown</td>
      <td>early</td>
      <td>37.0</td>
      <td>0.0</td>
      <td>247.0</td>
      <td>13.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>admin.</td>
      <td>single</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.0</td>
      <td>757.0</td>
      <td>343.0</td>
      <td>2.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>5</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>failure</td>
      <td>mid</td>
      <td>39.0</td>
      <td>-650.0</td>
      <td>123.0</td>
      <td>2.0</td>
      <td>364.0</td>
      <td>1.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>6</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>cellular</td>
      <td>apr</td>
      <td>unknown</td>
      <td>mid</td>
      <td>41.0</td>
      <td>5110.0</td>
      <td>231.0</td>
      <td>1.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>7</th>
      <td>admin.</td>
      <td>divorced</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>other</td>
      <td>mid</td>
      <td>31.0</td>
      <td>360.0</td>
      <td>332.0</td>
      <td>1.0</td>
      <td>297.0</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>8</th>
      <td>technician</td>
      <td>single</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.0</td>
      <td>454.0</td>
      <td>73.0</td>
      <td>3.0</td>
      <td>-1.0</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>9</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>mar</td>
      <td>failure</td>
      <td>mid</td>
      <td>37.0</td>
      <td>0.0</td>
      <td>129.0</td>
      <td>4.0</td>
      <td>107.0</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>





```python
cf_pd.head(10)
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>entrepreneur</td>
      <td>married</td>
      <td>secondary</td>
      <td>yes</td>
      <td>yes</td>
      <td>yes</td>
      <td>cellular</td>
      <td>aug</td>
      <td>unknown</td>
      <td>late</td>
      <td>52.712137</td>
      <td>-1746.000141</td>
      <td>92.5786</td>
      <td>6.0</td>
      <td>8.374012</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>1</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>other</td>
      <td>early</td>
      <td>50.354218</td>
      <td>2331.198414</td>
      <td>484.759748</td>
      <td>2.072403</td>
      <td>40.726143</td>
      <td>5.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>technician</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>unknown</td>
      <td>early</td>
      <td>50.418595</td>
      <td>1446.502151</td>
      <td>134.821164</td>
      <td>3.0</td>
      <td>3.786475</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>3</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>unknown</td>
      <td>jun</td>
      <td>unknown</td>
      <td>early</td>
      <td>37.0</td>
      <td>301.860751</td>
      <td>218.374873</td>
      <td>13.0</td>
      <td>10.835063</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>admin.</td>
      <td>single</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.269862</td>
      <td>856.063735</td>
      <td>331.255228</td>
      <td>2.0</td>
      <td>8.87659</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>5</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>failure</td>
      <td>mid</td>
      <td>39.442717</td>
      <td>-725.191141</td>
      <td>97.031301</td>
      <td>2.143867</td>
      <td>353.854774</td>
      <td>1.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>6</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
      <td>cellular</td>
      <td>apr</td>
      <td>unknown</td>
      <td>mid</td>
      <td>41.134654</td>
      <td>4988.577247</td>
      <td>209.49685</td>
      <td>1.0</td>
      <td>4.707964</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>7</th>
      <td>admin.</td>
      <td>divorced</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>other</td>
      <td>mid</td>
      <td>32.535061</td>
      <td>259.49417</td>
      <td>303.167226</td>
      <td>1.338418</td>
      <td>294.068386</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>8</th>
      <td>technician</td>
      <td>single</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>feb</td>
      <td>unknown</td>
      <td>early</td>
      <td>31.953464</td>
      <td>529.603574</td>
      <td>69.314435</td>
      <td>3.0</td>
      <td>6.261996</td>
      <td>0.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>9</th>
      <td>management</td>
      <td>married</td>
      <td>tertiary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>mar</td>
      <td>failure</td>
      <td>mid</td>
      <td>37.108863</td>
      <td>-467.506353</td>
      <td>89.334472</td>
      <td>4.051367</td>
      <td>101.834676</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>





```python
cf_pd['Label'].value_counts()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
    </tr>
    <tr>
      <th>Label</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>no</th>
      <td>98</td>
    </tr>
    <tr>
      <th>yes</th>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>



6.번에서와 같은 방식으로 원표본과 cf 100개를 각각 데이터 프레임으로 만들고 cf가 구해진 표본의 수를 세면, 이전 실행과 마찬가지로 Label이 yes인 표본은 2개이다. 제한조건을 소폭 완화해도 cf을 구하기는 쉽지 않다. 

한편 인덱스 35와 41에 대해서는 cf가 구해졌다. 표본의 원래 특성변수값과 비교하면, 두 표본 모두 ▲직업(job)이 ‘unknown’으로 변하고 ▲나이(age)가 약간 증가하고 ▲통장 잔고(balance)가 증가하고 ▲컨택의 통화시간(duration)이 길어지고 ▲이번 캠페인의 접촉(campaign)을 한 번 늘리고 ▲이전 마케팅캠페인으로부터 덜 경과한 시점(pdays)에 컨택했다면 정기예금 상품에 가입했을 것으로 예측되었다. 


```python
cf_pd[cf_pd['Label']=='yes']
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35</th>
      <td>unknown</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>oct</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4298.815915</td>
      <td>823.81039</td>
      <td>2.124269</td>
      <td>176.956274</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>41</th>
      <td>unknown</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>dec</td>
      <td>success</td>
      <td>mid</td>
      <td>36.843357</td>
      <td>2170.739222</td>
      <td>1305.3512</td>
      <td>1.807006</td>
      <td>164.917132</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>
</div>



```python
orig_pd.loc[[35, 41]]
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>apr</td>
      <td>success</td>
      <td>mid</td>
      <td>75.0</td>
      <td>3771.0</td>
      <td>185.0</td>
      <td>1.0</td>
      <td>181.0</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
    <tr>
      <th>41</th>
      <td>services</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>success</td>
      <td>mid</td>
      <td>34.0</td>
      <td>1076.0</td>
      <td>152.0</td>
      <td>1.0</td>
      <td>182.0</td>
      <td>6.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>




**하나의 표본에 대하여 여러개의 counterfactual 구하기**

다음은 정기예금 상품에 가입하지 않을 것으로 예측된 35번 표본에 대하여 여러개의 CFRL을 구하는 프로그램이다. diversity=True로 부여하고, num_samples=10을 지정하여 열 개의 cf를 구한다. 


```python
X = X_negative[35].reshape(1, -1)
explanation = explainer.explain(X=X, Y_t=Y_t, C=C, diversity=True, num_samples=10, batch_size=100)

orig = np.concatenate([explanation.data['orig']['X'], explanation.data['orig']['class']], axis=1)
cf = np.concatenate([explanation.data['cf']['X'], explanation.data['cf']['class']], axis=1)

orig_pd = pd.DataFrame(apply_category_mapping(orig, category_map), columns=feature_names)
cf_pd = pd.DataFrame(apply_category_mapping(cf, category_map), columns=feature_names)
```





```python
orig_pd.head()
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>apr</td>
      <td>success</td>
      <td>mid</td>
      <td>75.0</td>
      <td>3771.0</td>
      <td>185.0</td>
      <td>1.0</td>
      <td>181.0</td>
      <td>2.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>





아래 데이터프레임은 인덱스 35 표본에 대하여 구한 10개의 cf를 보여준다. cf 전반에 거쳐 경향성이 존재하는데, 고객의 통장 잔고는 현재보다 높은 수준이어야 하고 컨택의 통화시간 또한 길어져야 한다. 그럼에도 은행이 이 고객에게 정기예금 상품을 판매하기 위해 여러 cf 중 쉽게 실현가능한 시나리오를 선택할 수 있다는 점에서 CFRL은 의의가 있다. 예를 들어 나흘 뒤에(pdays==185) 한번 더 컨택하여(campaign==1.8)  800초 이상 통화함으로써(duration==807) 고객이 정기예금 상품에 가입할 확률을 높일 수 있다. 


```python
cf_pd.head(10)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>apr</td>
      <td>success</td>
      <td>mid</td>
      <td>75.000001</td>
      <td>4572.11824</td>
      <td>807.764809</td>
      <td>1.853142</td>
      <td>185.624958</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4443.198969</td>
      <td>836.134149</td>
      <td>1.037773</td>
      <td>179.452669</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4497.567884</td>
      <td>850.038117</td>
      <td>2.137861</td>
      <td>179.150466</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4502.672169</td>
      <td>849.145105</td>
      <td>2.034308</td>
      <td>185.801083</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4544.667332</td>
      <td>550.791157</td>
      <td>2.004443</td>
      <td>180.528057</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4574.388141</td>
      <td>853.189477</td>
      <td>1.886549</td>
      <td>184.557935</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4582.875336</td>
      <td>435.020543</td>
      <td>1.151441</td>
      <td>183.966158</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>7</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4583.943134</td>
      <td>864.700557</td>
      <td>1.914688</td>
      <td>187.831076</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>8</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4611.841174</td>
      <td>809.092029</td>
      <td>2.155101</td>
      <td>182.342586</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>9</th>
      <td>retired</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>telephone</td>
      <td>dec</td>
      <td>success</td>
      <td>late</td>
      <td>75.000001</td>
      <td>4625.385448</td>
      <td>641.303014</td>
      <td>2.07055</td>
      <td>184.602933</td>
      <td>2.0</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>
</div>




한편 인덱스 41에 대하여 여러 개의 CFRL 구하면 다음과 같다. 


```python
X = X_negative[41].reshape(1, -1)
explanation = explainer.explain(X=X, Y_t=Y_t, C=C, diversity=True, num_samples=10, batch_size=100)

orig = np.concatenate([explanation.data['orig']['X'], explanation.data['orig']['class']], axis=1)
cf = np.concatenate([explanation.data['cf']['X'], explanation.data['cf']['class']], axis=1)

orig_pd = pd.DataFrame(apply_category_mapping(orig, category_map), columns=feature_names)
cf_pd = pd.DataFrame(apply_category_mapping(cf, category_map), columns=feature_names)
```





```python
orig_pd.head()
```





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>services</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>may</td>
      <td>success</td>
      <td>mid</td>
      <td>34.0</td>
      <td>1076.0</td>
      <td>152.0</td>
      <td>1.0</td>
      <td>182.0</td>
      <td>6.0</td>
      <td>no</td>
    </tr>
  </tbody>
</table>
</div>




```python
cf_pd.head()
```


<div>
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>job</th>
      <th>marital</th>
      <th>education</th>
      <th>default</th>
      <th>housing</th>
      <th>loan</th>
      <th>contact</th>
      <th>month</th>
      <th>poutcome</th>
      <th>day_cat</th>
      <th>age</th>
      <th>balance</th>
      <th>duration</th>
      <th>campaign</th>
      <th>pdays</th>
      <th>previous</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>success</td>
      <td>mid</td>
      <td>36.051669</td>
      <td>2414.817902</td>
      <td>786.214626</td>
      <td>1.203718</td>
      <td>176.070671</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>aug</td>
      <td>success</td>
      <td>mid</td>
      <td>36.147542</td>
      <td>2573.402631</td>
      <td>1338.9051</td>
      <td>1.465826</td>
      <td>189.014606</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>2</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>dec</td>
      <td>success</td>
      <td>mid</td>
      <td>34.631865</td>
      <td>2676.180974</td>
      <td>1068.200258</td>
      <td>1.014127</td>
      <td>182.010006</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>dec</td>
      <td>success</td>
      <td>mid</td>
      <td>35.280412</td>
      <td>2192.127338</td>
      <td>607.713537</td>
      <td>1.499062</td>
      <td>170.209898</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>4</th>
      <td>admin.</td>
      <td>married</td>
      <td>secondary</td>
      <td>no</td>
      <td>no</td>
      <td>no</td>
      <td>cellular</td>
      <td>dec</td>
      <td>success</td>
      <td>mid</td>
      <td>35.335524</td>
      <td>2257.501848</td>
      <td>1436.361721</td>
      <td>1.449015</td>
      <td>166.697277</td>
      <td>6.0</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>
</div>




