# iris 데이터에 logistic regression을 적용(multi-class='ovr', multi-class='multinomial')하고 추정된 sigmoid 함수와 softmax 함수 제시

타겟변수 y가 두 개의 범주를 갖는 범주형 변수일 때(즉 y=0 또는 y=1), $p_i = Pr(y_i=1|x_i)$
- 그런데 $p_i$는 0~1 사이 값이고
- $z_i$ = $w^Tx_i$는 -무한대~+무한대의 값이므로

단순히 $p_i$를 특성변수 $x_i$에 대한 선형함수($z_i$)로 추정하는 것은 부적절하다. <br>
그러므로 log odds ratio인 $ln(\frac{p_i}{1-p_i})$를 특성변수의 선형으로 가정하면 <br>
$ln(\frac{p_i}{1-p_i})= z_i = w^Tx_i$ <br>
양변 모두 -무한대~+무한대의 값을 가지게 되므로 식이 성립한다. <br>
이 식을 pi에 대해 풀면 $p_i = \frac{1}{1+e^{-z_i}}$


```python
import seaborn as sns

iris = sns.load_dataset('iris')
X = iris.drop('species', axis=1)
y = iris['species']
#logit = LogisticRegression(
```


```python
from sklearn.preprocessing import LabelEncoder
classle = LabelEncoder()
y = classle.fit_transform(y.values)
```


```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1, stratify=y)
```


```python
# 표준화
from sklearn.preprocessing import StandardScaler
std = StandardScaler()
X_train_std = std.fit_transform(X_train) ## fit()과 transform() 한꺼번에 적용 
X_test_std = std.transform(X_test)
```

1\) LogisticRegression 클래스에서 multi_class 인자를 ‘ovr’로 지정하면 한 클래스와 나머지 클래스로 이항분류 쌍을 만들어 binary crossentropy를 구하며 특정 범주에 해당할 확률을 sigmoid 함수로 추정한다. 

$p_i = \frac{1}{1+e^{-w^Tx_i}}$

(여기서 $w^T x_i$는 특성변수의 가중치(w)와 특성변수 x의 선형결합을 의미한다.)

iris 데이터에 로지스틱 회귀를 적합하여 `intercept_` 속성을 출력하면  setosa-vs-rest, versicolor-vs-rest, virginica-vs-rest에 해당하는 w_0(즉 절편) 값을 확인할 수 있으며, 

`coef_` 속성을 출력하면  setosa-vr, versicolor-vr, virginica-vr을 행으로 하고 특성변수(sepal_length(x_1), sepal_width(x_2), petal_length(x_3), petal_width(x_4))를 열로 하여 특성변수의 계수를 추정한 매트릭스를 얻는다. 



```python
from sklearn.linear_model import LogisticRegression
Logit = LogisticRegression(C=1e2, random_state=1, multi_class='ovr')
l1 = Logit.fit(X_train_std, y_train)
print("=*=*= multi_class=ovr =*=*=")
print('intercept of setosa, versicolor, virginica\n', l1.intercept_.round(2))
print('sp_len, sp_wd, pt_len, pt_wd\n', l1.coef_.round(2))
```

    =*=*= multi_class=ovr =*=*=
    intercept of setosa, versicolor, virginica
     [ -5.43  -1.03 -12.22]
    sp_len, sp_wd, pt_len, pt_wd
     [[-2.27  2.04 -4.02 -3.46]
     [-1.28 -0.94  3.53 -2.24]
     [-0.31 -2.11  9.52  8.49]]


절편과 회귀계수로부터 sigmoid 함수를 추정하면 다음과 같다.

$$\hat{P}(Y_{setosa}=1)=  \frac{1}{1+e^{-(-5.43-2.27x_1+2.04x_2-4.02x_3-3.46x_4)}}=  \frac{1}{1+e^{(5.43+2.27x_1-2.04x_2+4.02x_3+3.46x_4) } }$$

$$\hat{P}(Y_{versicolor}=1)=  \frac{1}{1+e^{-(-1.03-1.28x_1-0.94x_2+3.53x_3-2.24x_4)}}=  \frac{1}{1+e^{(1.03+1.28x_1+0.94x_2-3.53x_3+2.24x_4) } }$$

$$\hat{P}(Y_{verginica}=1)=  \frac{1}{1+e^{-(-12.22-0.31x_1-2.11x_2+9.52x_3+8.49x_4)}}=  \frac{1}{1+e^{(12.22+0.31x_1+2.11x_2-9.52x_3-8.49x_4) } }$$

또한, 적합된 로직스틱 회귀 모형의 coef_속성으로부터 다음을 알 수 있다

ⅰ\) sepal_width(x_2)가 증가하면 setosa 범주에 속할 확률이 높아진다

ⅱ\) petal_length(x_3)가 증가하면 versicolor 범주에 속할 확률이 높아진다

ⅲ\) petal_length(x_3)와 petal_width(x_4)가 증가하면 virginica 범주에 속할 확률이 높아진다



```python
P = 1/(1+e^(-z))
z = intercept + B1*sepal_length + B2*sepal_width + B3*petal_length + B4*petal_width

```


```python
Logit2 = LogisticRegression(C=1e2, random_state=1, multi_class='multinomial')
l2 = Logit2.fit(X_train_std, y_train)
print("=*=*= multi_class=multinomial =*=*=")
print('intercept of setosa, versicolor, virginica\n', l2.intercept_.round(2))
print('sp_len, sp_wd, pt_len, pt_wd\n', l2.coef_.round(2))
```

    =*=*= multi_class=multinomial =*=*=
    intercept of setosa, versicolor, virginica
     [ 0.6   6.11 -6.71]
    sp_len, sp_wd, pt_len, pt_wd
     [[-2.49  2.41 -5.42 -4.83]
     [ 1.46 -0.13 -2.35 -2.01]
     [ 1.02 -2.28  7.77  6.84]]


이로부터 softmax 함수를 추정하면 다음과 같다.

$$w_{setosa} = (0.60, -2.49, 2.41, -5.42, -4.83)^T$$

$$w_{versicolor} = (6.11, 1.46, -0.13, -2.35, -2.01)^T$$

$$w_{virginica} = (-6.71, 1.02, -2.28, 7.77, 6.84)^T$$

$$\hat{P}(Y=k) = \frac{e^{w^T_kx_i}}{e^{w^T_{setosa}x_i + w^T_{versicolor}x_i + w^T_{virginica}x_i}}, 
k =
\begin{cases}
\textit{setosa} \\
\textit{versicolor} \\
\textit{virginica}
\end{cases}
$$

한편, 적합된 로지스틱 회귀 모형의 coef_ 속성으로부터 다음을 알 수 있다. 

ⅰ) {setosa, versicolor, virginica} 중 setosa 범주에 속할 확률은 sepal_width(x_2)가 증가할수록 높아진다

ⅱ) {setosa, versicolor, virginica} 중 versicolor 범주에 속할 확률은 sepal_length(x_1)가 증가할수록 높아진다

ⅲ) {setosa, versicolor, virginica} 중 virginica 범주에 속할 확률은 sepal_length(x_1), petal_length(x_3), petal_width(x_4)가 증가할수록 높아진다

