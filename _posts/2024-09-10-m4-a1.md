---
layout: single
title: "Global Explainers: PD, PV and PI"
categories: XAI
sidebar: true
use_math: true
---

# adult census 데이터를 사용하여 Global Explainers 구현

## 0. 필요한 클래스와 함수 불러오기


```python
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score, roc_auc_score
from alibi.explainers import PartialDependence, plot_pd, PartialDependenceVariance, plot_pd_variance, PermutationImportance, plot_permutation_importance
```

## 1. 데이터 확인
- 주의: 원본 csv 파일의 첫 행에 컬럼명이 없으므로 header=None 지정

csv 형식의 adult_census 데이터 pandas Data Frame으로 읽어들이고 컬럼명을 부여한다. 데이터프레임의 info() 메서드를 통해 각 컬럼의 null 포함 여부와 데이터타입을 확인하고 describe() 메서드를 통해 연속현 특성변수의 요약통계량을 확인한다. 특성변수 중 ‘fnlwgt’는 샘플 가중치이므로 무시하기로 한다. 


```python
df = pd.read_csv('adult_census.csv', header=None)
# Define df_census columns
df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',
                  'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 
                   'income']

# Display first 5 rows
df.head()

```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>Handlers-cleaners</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>3</th>
      <td>53</td>
      <td>Private</td>
      <td>234721</td>
      <td>11th</td>
      <td>7</td>
      <td>Married-civ-spouse</td>
      <td>Handlers-cleaners</td>
      <td>Husband</td>
      <td>Black</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>4</th>
      <td>28</td>
      <td>Private</td>
      <td>338409</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Wife</td>
      <td>Black</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>Cuba</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 32561 entries, 0 to 32560
    Data columns (total 15 columns):
     #   Column          Non-Null Count  Dtype 
    ---  ------          --------------  ----- 
     0   age             32561 non-null  int64 
     1   workclass       32561 non-null  object
     2   fnlwgt          32561 non-null  int64 
     3   education       32561 non-null  object
     4   education-num   32561 non-null  int64 
     5   marital-status  32561 non-null  object
     6   occupation      32561 non-null  object
     7   relationship    32561 non-null  object
     8   race            32561 non-null  object
     9   sex             32561 non-null  object
     10  capital-gain    32561 non-null  int64 
     11  capital-loss    32561 non-null  int64 
     12  hours-per-week  32561 non-null  int64 
     13  native-country  32561 non-null  object
     14  income          32561 non-null  object
    dtypes: int64(6), object(9)
    memory usage: 3.7+ MB



```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>fnlwgt</th>
      <th>education-num</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>32561.000000</td>
      <td>3.256100e+04</td>
      <td>32561.000000</td>
      <td>32561.000000</td>
      <td>32561.000000</td>
      <td>32561.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>38.581647</td>
      <td>1.897784e+05</td>
      <td>10.080679</td>
      <td>1077.648844</td>
      <td>87.303830</td>
      <td>40.437456</td>
    </tr>
    <tr>
      <th>std</th>
      <td>13.640433</td>
      <td>1.055500e+05</td>
      <td>2.572720</td>
      <td>7385.292085</td>
      <td>402.960219</td>
      <td>12.347429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>17.000000</td>
      <td>1.228500e+04</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>28.000000</td>
      <td>1.178270e+05</td>
      <td>9.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>40.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>37.000000</td>
      <td>1.783560e+05</td>
      <td>10.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>40.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>48.000000</td>
      <td>2.370510e+05</td>
      <td>12.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>45.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>90.000000</td>
      <td>1.484705e+06</td>
      <td>16.000000</td>
      <td>99999.000000</td>
      <td>4356.000000</td>
      <td>99.000000</td>
    </tr>
  </tbody>
</table>
</div>



##### <span style="color: plum">목적변수의 분포 파악</span>
- income>50K가 전체의 24.08%로 소수클래스이므로 모형 적합 시 이러한 불균형을 고려해야 한다
- 모형의 성능이 데이터의 불균형에 영향을 덜 받으려면 성능 측정을 accuracy 대신 precision, recall 또는 f1 score로 해야 한다


```python
target_perc = df['income'].value_counts(normalize=True).mul(100).rename('percent').reset_index() 
target_perc
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>income</th>
      <th>percent</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&lt;=50K</td>
      <td>75.919044</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;50K</td>
      <td>24.080956</td>
    </tr>
  </tbody>
</table>
</div>




```python
g = sns.catplot(data = target_perc, x='income', y='percent', kind='bar')
g.ax.set_ylim(0, 100)

for p in g.ax.patches:
    txt = str(p.get_height().round(2)) + '%'
    txt_x, txt_y = p.get_x(), p.get_height()
    g.ax.text(x = txt_x, y=txt_y, s = txt, fontdict={'size': 15})
```


    
![png](output_8_0.png)
    


## 2.explainer를 적용하기 위한 특성변수명, 목적변수명, 범주형 특성변수의 index 정의
원본 데이터프레임과 비교하면 범주형인 workclass(인덱스 1), education(인덱스 3) 등이 categorical_column_indices에 제대로 포함되었음을 확인할 수 있다. 


```python
# 목적변수
target_name = 'income'
# 전체 특성변수
feature_names = df.columns.to_list()
feature_names.remove(target_name)
# 범주형 특성변수 
categorical_column_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']
numerical_names = [ft for ft in feature_names if ft not in categorical_column_names]
# 범주형 및 실수형 컬럼의 인덱스
categorical_column_indices = [feature_names.index(ft) for ft in categorical_column_names]
numerical_column_indices = [feature_names.index(ft) for ft in feature_names 
                     if ft not in categorical_column_names]

print(categorical_column_indices)
print(numerical_column_indices)

```

    [1, 3, 5, 6, 7, 8, 9, 13]
    [0, 2, 4, 10, 11, 12]


## 3. 전처리
- 목적변수인 ‘income’의 변수값이 ‘<=50K’와 ‘>50K’로 입력되어 있으므로 숫자 0과 1로 매핑한다. 단, 변수값에 공백(whitespace)이 있으므로 strip을 적용해야 안정적으로 매핑할 수 있다. 
- 범주형 특성변수의 변수값은 문자열로 입력되어 있으므로 이를 순서형 정수로 변환하는 OrdinalEncoder 클래스의 인스턴스를 사용한다. 
- 또한 alibi의 explainer는 numpy 데이터형만 입력으로 받으므로 pandas DataFrame을 numpy로 변환한다. 
- 학습데이터와 시험데이터로 분할할 때에는 불균형 데이터임을 고려하여 층화(stratify)추출로 지정한다. 



```python
df['income'] = df['income'].str.strip().map({"<=50K": 0, ">50K": 1})

# X, y 정의
X = df[feature_names]
y = df[target_name]

# ordinal encoding
oe = OrdinalEncoder().fit(X[categorical_column_names])
# print(oe.categories_)
X.loc[ : , categorical_column_names] = oe.transform(X[categorical_column_names])

# numpy로 변환
X = X.to_numpy()
y = y.to_numpy()

# 학습데이터와 시험데이터로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=0)

```


```python
# 데이터프레임에 다시 한 번 info() 메서드를 호출하여 ‘income’의 데이터타입이 int64로 변환되었음을 확인한다. 
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 32561 entries, 0 to 32560
    Data columns (total 15 columns):
     #   Column          Non-Null Count  Dtype 
    ---  ------          --------------  ----- 
     0   age             32561 non-null  int64 
     1   workclass       32561 non-null  object
     2   fnlwgt          32561 non-null  int64 
     3   education       32561 non-null  object
     4   education-num   32561 non-null  int64 
     5   marital-status  32561 non-null  object
     6   occupation      32561 non-null  object
     7   relationship    32561 non-null  object
     8   race            32561 non-null  object
     9   sex             32561 non-null  object
     10  capital-gain    32561 non-null  int64 
     11  capital-loss    32561 non-null  int64 
     12  hours-per-week  32561 non-null  int64 
     13  native-country  32561 non-null  object
     14  income          32561 non-null  int64 
    dtypes: int64(7), object(8)
    memory usage: 3.7+ MB


- <span style="color: magenta">alibi.utils 패키지의 gen_category_map 함수를 사용하면 PartialDependence 인스턴스 생성 시 필요한 categorical_names 파라미터에 넘겨줄 dictionary를 쉽게 만들 수 있다.</span>


```python
from alibi.utils import gen_category_map
categorical_names = gen_category_map(data=df, categorical_columns=categorical_column_indices)

type(categorical_names)
```




    dict




```python
categorical_names
```




    {1: [' ?',
      ' Federal-gov',
      ' Local-gov',
      ' Never-worked',
      ' Private',
      ' Self-emp-inc',
      ' Self-emp-not-inc',
      ' State-gov',
      ' Without-pay'],
     3: [' 10th',
      ' 11th',
      ' 12th',
      ' 1st-4th',
      ' 5th-6th',
      ' 7th-8th',
      ' 9th',
      ' Assoc-acdm',
      ' Assoc-voc',
      ' Bachelors',
      ' Doctorate',
      ' HS-grad',
      ' Masters',
      ' Preschool',
      ' Prof-school',
      ' Some-college'],
     5: [' Divorced',
      ' Married-AF-spouse',
      ' Married-civ-spouse',
      ' Married-spouse-absent',
      ' Never-married',
      ' Separated',
      ' Widowed'],
     6: [' ?',
      ' Adm-clerical',
      ' Armed-Forces',
      ' Craft-repair',
      ' Exec-managerial',
      ' Farming-fishing',
      ' Handlers-cleaners',
      ' Machine-op-inspct',
      ' Other-service',
      ' Priv-house-serv',
      ' Prof-specialty',
      ' Protective-serv',
      ' Sales',
      ' Tech-support',
      ' Transport-moving'],
     7: [' Husband',
      ' Not-in-family',
      ' Other-relative',
      ' Own-child',
      ' Unmarried',
      ' Wife'],
     8: [' Amer-Indian-Eskimo',
      ' Asian-Pac-Islander',
      ' Black',
      ' Other',
      ' White'],
     9: [' Female', ' Male'],
     13: [' ?',
      ' Cambodia',
      ' Canada',
      ' China',
      ' Columbia',
      ' Cuba',
      ' Dominican-Republic',
      ' Ecuador',
      ' El-Salvador',
      ' England',
      ' France',
      ' Germany',
      ' Greece',
      ' Guatemala',
      ' Haiti',
      ' Holand-Netherlands',
      ' Honduras',
      ' Hong',
      ' Hungary',
      ' India',
      ' Iran',
      ' Ireland',
      ' Italy',
      ' Jamaica',
      ' Japan',
      ' Laos',
      ' Mexico',
      ' Nicaragua',
      ' Outlying-US(Guam-USVI-etc)',
      ' Peru',
      ' Philippines',
      ' Poland',
      ' Portugal',
      ' Puerto-Rico',
      ' Scotland',
      ' South',
      ' Taiwan',
      ' Thailand',
      ' Trinadad&Tobago',
      ' United-States',
      ' Vietnam',
      ' Yugoslavia']}




```python
# 인덱스 1 칼럼의 모든 변수값이 제대로 들어갔음을 확인 
df.iloc[:, 1].value_counts()
```




    workclass
    Private             22696
    Self-emp-not-inc     2541
    Local-gov            2093
    ?                    1836
    State-gov            1298
    Self-emp-inc         1116
    Federal-gov           960
    Without-pay            14
    Never-worked            7
    Name: count, dtype: int64



## 4. 실수형 및 범주형 특성변수 정제
ColumnTransformer를 이용하여 (1) 실수형 특성변수는 표준화 하고 (2) 범주형 특성변수는 one-hot encoding 한다. 
- 실수형 특성변수의 경우 표준화 과정이 강제적이지 않지만 df.describe()로 확인 시 변수 간 값 범위가 크게 차이나므로 표준화 하는 편이 낫다고 판단, StandardScaler 클래스를 호출하여 표준화 한다. 
- 범주형 특성변수의 경우, 이항범주이면 굳이 컬럼을 두 개 생성하지 않고 하나만 생성하도록 drop=’if_binary’로 지정한다. 


```python
for key in categorical_names:
    categorical_names[key] = [value.strip() for value in categorical_names[key]]
    
categorical_names
```




    {1: ['?',
      'Federal-gov',
      'Local-gov',
      'Never-worked',
      'Private',
      'Self-emp-inc',
      'Self-emp-not-inc',
      'State-gov',
      'Without-pay'],
     3: ['10th',
      '11th',
      '12th',
      '1st-4th',
      '5th-6th',
      '7th-8th',
      '9th',
      'Assoc-acdm',
      'Assoc-voc',
      'Bachelors',
      'Doctorate',
      'HS-grad',
      'Masters',
      'Preschool',
      'Prof-school',
      'Some-college'],
     5: ['Divorced',
      'Married-AF-spouse',
      'Married-civ-spouse',
      'Married-spouse-absent',
      'Never-married',
      'Separated',
      'Widowed'],
     6: ['?',
      'Adm-clerical',
      'Armed-Forces',
      'Craft-repair',
      'Exec-managerial',
      'Farming-fishing',
      'Handlers-cleaners',
      'Machine-op-inspct',
      'Other-service',
      'Priv-house-serv',
      'Prof-specialty',
      'Protective-serv',
      'Sales',
      'Tech-support',
      'Transport-moving'],
     7: ['Husband',
      'Not-in-family',
      'Other-relative',
      'Own-child',
      'Unmarried',
      'Wife'],
     8: ['Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'],
     9: ['Female', 'Male'],
     13: ['?',
      'Cambodia',
      'Canada',
      'China',
      'Columbia',
      'Cuba',
      'Dominican-Republic',
      'Ecuador',
      'El-Salvador',
      'England',
      'France',
      'Germany',
      'Greece',
      'Guatemala',
      'Haiti',
      'Holand-Netherlands',
      'Honduras',
      'Hong',
      'Hungary',
      'India',
      'Iran',
      'Ireland',
      'Italy',
      'Jamaica',
      'Japan',
      'Laos',
      'Mexico',
      'Nicaragua',
      'Outlying-US(Guam-USVI-etc)',
      'Peru',
      'Philippines',
      'Poland',
      'Portugal',
      'Puerto-Rico',
      'Scotland',
      'South',
      'Taiwan',
      'Thailand',
      'Trinadad&Tobago',
      'United-States',
      'Vietnam',
      'Yugoslavia']}




```python
preprocessor = ColumnTransformer([("num", 
                                   StandardScaler(), 
                                   numerical_column_indices), 
                                  ("cat", 
                                   OneHotEncoder(sparse_output=False, drop='if_binary', handle_unknown='ignore'),
                                   categorical_column_indices)])

preprocessor.fit(X_train)

X_train_ohe = preprocessor.transform(X_train)
X_test_ohe = preprocessor.transform(X_test)
```

## 5. 모형 적합
목적변수인 ‘income’이 1(“>50K”) 또는 0(“<=50K”)이므로 random forest 모형에 적합시킨다. 불균형 데이터이므로 class_weight을 ‘balanced’로 지정한다. 


```python
rf = RandomForestClassifier(class_weight='balanced', random_state=0)
rf.fit(X_train_ohe, y_train)

y_train_hat = rf.predict(X_train_ohe)
print(classification_report(y_true=y_train, y_pred=y_train_hat))
```

                  precision    recall  f1-score   support
    
               0       1.00      1.00      1.00     19775
               1       1.00      1.00      1.00      6273
    
        accuracy                           1.00     26048
       macro avg       1.00      1.00      1.00     26048
    weighted avg       1.00      1.00      1.00     26048
    


모형의 성능이 그닥 좋지 않다. 특히 소수클래스에 대한 예측력이 떨어진다


```python
y_test_hat = rf.predict(X_test_ohe)
print(classification_report(y_true=y_test, y_pred=y_test_hat))
```

                  precision    recall  f1-score   support
    
               0       0.88      0.93      0.91      4945
               1       0.74      0.60      0.67      1568
    
        accuracy                           0.85      6513
       macro avg       0.81      0.77      0.79      6513
    weighted avg       0.85      0.85      0.85      6513
    


## 6.1 Partial Dependence
alibi의 PD는 블랙박스 모형을 가정하므로 예측함수(predictor=)를 넘겨주어야 한다. 아래와 같이 예측함수를 정의한다. 


```python
prediction_fn = lambda x: rf.predict(preprocessor.transform(x))
```

Alibi에서 불러온 PartialDependence 클래스를 인스턴스화 한다. 한편 PD를 구할 변수에 ‘fnlwgt’(Current Population Survey 가중치)와 ‘education-num’(education 변수와 사실상 중복) 변수를 제외하였다. 


```python
target_name = ['income']
explainer = PartialDependence(predictor=prediction_fn,
                              feature_names=feature_names,
                              target_names=target_name,
                              categorical_names=categorical_names)
```

PartialDependence 클래스의 인스턴스에 explain 메서드를 호출한다. 이 때 $X_{-i}$의 주변분포(marginal distribution)를 가장 잘 대표하는 데이터가 학습데이터이므로 X=X_train으로 지정한다. 


```python
features = [feature_names.index('age'),
            feature_names.index('workclass'),
            feature_names.index('education'),
            feature_names.index('marital-status'),
            feature_names.index('occupation'),
            feature_names.index('relationship'),
            feature_names.index('race'),
            feature_names.index('sex'),
            feature_names.index('hours-per-week'),
            feature_names.index('native-country'),
            feature_names.index('capital-gain'),
            feature_names.index('capital-loss')
            ]
exp_pd_avg = explainer.explain(X = X_train, features = features, kind='average')
```

. plot_pd 함수를 사용하여 특성변수의 PD를 그린다. 이어지는 페이지의 그림으로부터 다음을 유추할 수 있다. 
-	소득이 50K를 초과할 기댓값은 연령이 높아질수록 함께 높아지다가 은퇴가 시작되는 50대 후반부터 점차 낮아진다 
-	직업으로 살펴보면, 관리직(Exec-magagerial)과 기술지원(Tech-support) 직군에서 소득이 50K를 초과할 기댓값이 타 직군보다 높다
-	주당 노동시간이 30시간일 때부터 소득이 50K를 초과할 기댓값이 점차 높아지나, 40시간 이상 구간에서는 거의 일정하다
-	출신 지역으로는 Mexico 출신인 경우 소득이 50K를 초과할 기댓값이 확연히 낮다



```python
plot_pd(exp = exp_pd_avg, fig_kw={'figheight': 25, 'figwidth': 10}, n_cols=2)
```




    array([[<Axes: xlabel='age', ylabel='income'>,
            <Axes: xlabel='workclass', ylabel='income'>],
           [<Axes: xlabel='education', ylabel='income'>,
            <Axes: xlabel='marital-status', ylabel='income'>],
           [<Axes: xlabel='occupation', ylabel='income'>,
            <Axes: xlabel='relationship', ylabel='income'>],
           [<Axes: xlabel='race', ylabel='income'>,
            <Axes: xlabel='sex', ylabel='income'>],
           [<Axes: xlabel='hours-per-week', ylabel='income'>,
            <Axes: xlabel='native-country', ylabel='income'>],
           [<Axes: xlabel='capital-gain', ylabel='income'>,
            <Axes: xlabel='capital-loss', ylabel='income'>]], dtype=object)




    
![png](output_32_1.png)
    


분류 모델이기 때문에(목적변수가 0 또는 1) kind-'individual' 또는 kind='both'를 그리는 건 별로 의미가 없으므로 kind='average'로 지정하여 교호작용을 시각화 한다. 아래 그림은 차례로 race:gender, education:occupation, gender:occupation의 교호작용을 보여준다. 


```python
feature_interaction = [(feature_names.index('race'), feature_names.index('sex')),
                       (feature_names.index('education'), feature_names.index('occupation')),
                       (feature_names.index('sex'), feature_names.index('occupation'))
                       ]

exp_pd_interaction = explainer.explain(X = X_train, features = feature_interaction, kind='average')
```


```python

import matplotlib.pyplot as plt 
colors = plt.cm.tab20b.colors 

plot_pd(exp = exp_pd_interaction, 
        n_cols=1, 
        fig_kw={'figheight': 20, 'figwidth': 10},
        pd_cat_kw={'color': colors})
```




    array([[<Axes: xlabel='sex', ylabel='race'>],
           [<Axes: xlabel='occupation', ylabel='education'>],
           [<Axes: xlabel='occupation', ylabel='sex'>]], dtype=object)




    
![png](output_35_1.png)
    


## 6.2 Partial Dependence Variance
PV는 각 특성변수의 변수값에 따라 측정된 PD값의 표준편차로, PV가 클수록 해당 특성변수의 중요도가 높다. 앞서 살펴본 PD 플롯에서 좌하단 capital-gain이 넓은 범위의 값을 가짐을 확인한 바, 아래 PV 플롯에서도 capital-gain 변수의 PV가 가장 높게 나타난다. 그 외 교육을 받은 햇수를 뜻하는 education-num, 주당 노동시간(hours-per-week), 연령(age) 또한 PV가 높은 즉 중요한 변수이다. 


```python
target_name=['income']
explainer_pv = PartialDependenceVariance(predictor=prediction_fn,
                                        feature_names=feature_names,
                                        categorical_names=categorical_names,
                                        target_names=target_name)

exp_pv_importance_all = explainer_pv.explain(X=X_train, method='importance')

plot_pd_variance(exp = exp_pv_importance_all)

```




    array([[<Axes: title={'center': 'income'}, xlabel='Feature importance'>]],
          dtype=object)




    
![png](output_37_1.png)
    



```python
exp_pv_interaction = explainer_pv.explain(X = X_train,
                                          features = feature_interaction, 
                                          method='interaction')
```


```python
plot_pd_variance(exp=exp_pv_interaction, summarise=False, fig_kw={'figheight': 15, 'figwidth': 20})
```




    array([[<Axes: title={'center': 'inter(education,occupation) = 0.011'}, xlabel='occupation', ylabel='education'>,
            <Axes: title={'center': 'inter(occupation|education) = 0.011'}, xlabel='education', ylabel='income'>,
            <Axes: title={'center': 'inter(education|occupation) = 0.012'}, xlabel='occupation', ylabel='income'>],
           [<Axes: title={'center': 'inter(sex,occupation) = 0.002'}, xlabel='occupation', ylabel='sex'>,
            <Axes: title={'center': 'inter(occupation|sex) = 0.002'}, xlabel='sex', ylabel='income'>,
            <Axes: title={'center': 'inter(sex|occupation) = 0.002'}, xlabel='occupation', ylabel='income'>],
           [<Axes: title={'center': 'inter(race,sex) = 0.000'}, xlabel='sex', ylabel='race'>,
            <Axes: title={'center': 'inter(sex|race) = 0.001'}, xlabel='race', ylabel='income'>,
            <Axes: title={'center': 'inter(race|sex) = 0.000'}, xlabel='sex', ylabel='income'>]],
          dtype=object)




    
![png](output_39_1.png)
    


## 6.3 Permutation Importance
Partial Dependence, Partial Dependence Variance와 달리 Permutation Importance 인스턴스가 explain 메서드를 호출할 때에는 X 파라미터에 주로 `X_test`를 사용한다. 한편 explain() 메서드의 kind 파라미터 값이 디폴트인 ‘ratio’이기 때문에 $MR(M)=\frac{e_{switch}(M)}{e_{orig}(M)}$을 구한다. 따라서 PI가 1인 특성변수는 모형의 손실함수값을 줄이는 데 기여하지 못한다고 해석할 수 있다. 



```python
explainer_pi = PermutationImportance(predictor = prediction_fn,
                                     score_fns=['accuracy', 'f1'],
                                     feature_names=feature_names,
                                     verbose=True)

exp_pi = explainer_pi.explain(X = X_test, y=y_test, kind='ratio')
```

    100%|██████████| 14/14 [01:01<00:00,  4.37s/it]


### 6.3.1 score functions을 accuracy와 f1으로 지정한 경우
아래 플롯으로부터 score function에 따라 특성변수 중요도가 다르게 나타남을 확인할 수 있다.


```python
plot_permutation_importance(exp = exp_pi, n_cols=2, fig_kw={'figheight': 5, 'figwidth': 10})
```




    array([[<Axes: title={'center': 'accuracy'}, xlabel='Permutation feature importance'>,
            <Axes: title={'center': 'f1'}, xlabel='Permutation feature importance'>]],
          dtype=object)




    
![png](output_43_1.png)
    


### 6.3.2 score function으로 1-f1을 지정할 경우


```python
def loss_f1(y_true: np.ndarray, y_pred: np.ndarray):
    return 1-f1_score(y_true=y_true, y_pred=y_pred)

explainer_pi_loss_f1 = PermutationImportance(predictor=prediction_fn, 
                                             loss_fns={'1-f1': loss_f1}, 
                                             feature_names=feature_names,
                                             verbose=True)

exp_pi_loss_f1 = explainer_pi_loss_f1.explain(X = X_test, y=y_test)
```

    100%|██████████| 14/14 [01:01<00:00,  4.41s/it]



```python
plot_permutation_importance(exp = exp_pi_loss_f1)
```




    array([[<Axes: title={'center': '1-f1'}, xlabel='Permutation feature importance'>]],
          dtype=object)




    
![png](output_46_1.png)
    


### 6.3.3 score function으로 1-roc_auc를 지정한 경우
roc_auc가 확률로 계산되므로 PermutationImportance 인스턴스 생성 시 예측함수(predictor 파라미터)를 rf.predict_proba로 주어야 한다


```python
def loss_auc(y_true: np.ndarray, y_score: np.ndarray):
    return 1 - roc_auc_score(y_true=y_true, y_score=y_score)
def proba_fn(X: np.ndarray):
    return rf.predict_proba(preprocessor.transform(X))[ : ,1]

explainer_pi_loss_auc = PermutationImportance(predictor=proba_fn, 
                                              loss_fns={'1-auc': loss_auc}, 
                                              feature_names=feature_names,
                                              verbose=True)

exp_pi_loss_auc = explainer_pi_loss_auc.explain(X = X_test, y=y_test)


```

    100%|██████████| 14/14 [01:02<00:00,  4.48s/it]



```python
plot_permutation_importance(exp=exp_pi_loss_auc)
```




    array([[<Axes: title={'center': '1-auc'}, xlabel='Permutation feature importance'>]],
          dtype=object)




    
![png](output_49_1.png)
    


방법 2와 방법 3의 PI가 상이하다. 즉, PI는 손실함수 선택에 따라 특성변수 중요도가 다르게 나타날 수 있으므로 2개 이상의 손실함수(또는 score)를 PI에 적용하여 특성변수의 중요도를 결정해야 한다
