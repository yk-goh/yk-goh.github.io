---
layout: single
title: "Comparision between `weights` arguments('distance' and 'uniform') in KNN"
categories: ML
sidebar: true
use_math: true
---

## 문제: iris 데이터를 이용하여 KNN에서 weights='distance'로 준 경우와 'uniform'(default)인 경우를 비교
> 일반적으로 KNN의 weight는 distance가 uniform보다 통계적으로 합리적이다


```python
import seaborn as sns
iris = sns.load_dataset('iris')
iris.head()
```




<div>
  <style scoped>
      .dataframe tbody tr th:only-of-type {
          vertical-align: middle;
      }
  
      .dataframe tbody tr th {
          vertical-align: top;
      }
  
      .dataframe thead th {
          text-align: right;
      }
  </style>
  <table border="1" class="dataframe">
    <thead>
      <tr style="text-align: right;">
        <th></th>
        <th>sepal_length</th>
        <th>sepal_width</th>
        <th>petal_length</th>
        <th>petal_width</th>
        <th>species</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>0</th>
        <td>5.1</td>
        <td>3.5</td>
        <td>1.4</td>
        <td>0.2</td>
        <td>setosa</td>
      </tr>
      <tr>
        <th>1</th>
        <td>4.9</td>
        <td>3.0</td>
        <td>1.4</td>
        <td>0.2</td>
        <td>setosa</td>
      </tr>
      <tr>
        <th>2</th>
        <td>4.7</td>
        <td>3.2</td>
        <td>1.3</td>
        <td>0.2</td>
        <td>setosa</td>
      </tr>
      <tr>
        <th>3</th>
        <td>4.6</td>
        <td>3.1</td>
        <td>1.5</td>
        <td>0.2</td>
        <td>setosa</td>
      </tr>
      <tr>
        <th>4</th>
        <td>5.0</td>
        <td>3.6</td>
        <td>1.4</td>
        <td>0.2</td>
        <td>setosa</td>
      </tr>
    </tbody>
  </table>
</div>




```python
X = iris.drop('species', axis=1)
y = iris['species']

# 실수화
from sklearn.preprocessing import LabelEncoder
import numpy as np

classle = LabelEncoder() # instantiation of LabelEncoder class
y = classle.fit_transform(iris['species'].values)
print('species labels:', np.unique(y))
yo = classle.inverse_transform(y) # 원래의 문자열로 전환
print('species_original:', np.unique(yo))
```

    species labels: [0 1 2]
    species_original: ['setosa' 'versicolor' 'virginica']



```python
# split into train set and test set.
from sklearn.model_selection import train_test_split
# 층화추출
X_train, X_test, y_train, y_test = \
  train_test_split(X, y, test_size=.3, random_state=1, stratify = y)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
```

    (105, 4)
    (45, 4)
    (105,)
    (45,)


### 1) weights = 'uniform' (default)


```python
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5, p=2, weights='uniform')
# 학습
knn.fit(X_train, y_train)

# test set에 적용(predict)
y_train_pred = knn.predict(X_train)
y_test_pred = knn.predict(X_test)
print('(Uniform weight) Mis-classified training samples: %d' %(y_train!=y_train_pred).sum())
print('(Uniform weight) Mis-classified test samples: %d' %(y_test!=y_test_pred).sum())
```

    (Uniform weight) Mis-classified training samples: 2
    (Uniform weight) Mis-classified test samples: 1



```python
# 정확도 확인 - confusion matrix
"""
          열: 예측값
          0  1  2
행: 참값  0
        1
        2
"""
from sklearn.metrics import confusion_matrix
conf = confusion_matrix(y_true=y_test, y_pred=y_test_pred)
print(conf)
# 참값이 [2]인데 [1]로 예측한 케이스가 하나 있음 
```

    [[15  0  0]
     [ 0 15  0]
     [ 0  1 14]]



```python
# 정확도 계산 - accuracy score
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_test_pred).round(2))
"""
정확하게 예측한 샘플 수 / 전체 샘플 수
imbalanced data에서는 사용하면 안됨! 
100명 중 1명이 코로나일 때, 모델이 무조건 '코로나아님'이라고 진단하면 99% accuracy를 가짐.
"""
```

    0.98


### 2) weights = 'distance'


```python
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5, p=2, weights='distance')
# 학습
knn.fit(X_train, y_train)

# test set에 적용(predict)
y_train_pred = knn.predict(X_train)
y_test_pred = knn.predict(X_test)
print('(Distance weight) Mis-classified training samples: %d' %(y_train!=y_train_pred).sum())
print('(Distance weight) Mis-classified test samples: %d' %(y_test!=y_test_pred).sum())
```

    (Distance weight) Mis-classified training samples: 0
    (Distance weight) Mis-classified test samples: 1



```python
# 정확도 확인 - confusion matrix
from sklearn.metrics import confusion_matrix
conf = confusion_matrix(y_true=y_test, y_pred=y_test_pred)
print(conf)
# 참값이 [2]인데 [1]로 예측한 케이스가 하나 있음 

# 정확도 계산 - accuracy score
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_test_pred).round(2))
```

    [[15  0  0]
     [ 0 15  0]
     [ 0  1 14]]
    0.98


---
- training datset에서 knn의 weight='distance'로 했을 때 uniform으로 했을 때보다 잘 적합되었다(training dataset에서 오분류 된 표본 수가 weights=’uniform’의 경우 2개, weights=’distance’의 경우 0개).<br>
그러나 test dataset에서의 성능 차이는 보이지 않았다. confusion matrix를 살펴보면, 두 가지 weight 방식에서 모두 실제값이 세 번째 클래스인 관측치 하나를 두 번째 클래스로 잘못 분류하였다.
- 가중치를 distance로 준 경우(거리에 비례) train set에서 오분류 0개, test set에서 오분류 1개로 test set에서의 성능이 train set에서의 성능보다 낮아 과대적합이 의심된다. 


