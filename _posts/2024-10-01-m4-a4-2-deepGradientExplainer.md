---
layout: single
title: "Deep Explainer and Gradient Explainer"
categories: XAI
sidebar: true
use_math: true
---


# Deep Explainer and Gradient Explainer on Boston-housingÂ data

## 0. import libraries and data


```python
# %pip install shap
```


```python
import pandas as pd
import numpy as np
import shap 
from sklearn.linear_model import LinearRegression

# scientific notation(ìì—°ìƒìˆ˜ eë¥¼ ì‚¬ìš©í•´ì„œ í‘œí˜„í•˜ëŠ” ê²ƒ)ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ì†Œìˆ˜ì  ì•„ë˜ ì„¸ ìë¦¬ê¹Œì§€ í‘œê¸°í•œë‹¤.
np.set_printoptions(suppress=True, precision=3)
# shap ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹œê°í™”ë¥¼ ìœ„í•œ ìë°”ìŠ¤í¬ë¦½íŠ¸ í™œì„±í™” 
shap.initjs()

```





```python
df = pd.read_csv('/Users/ykgoh/Documents/Module 4/XAI/materials/section3_rev/Boston.csv', index_col=0)
df.head()
```




<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>PRICE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
  </tbody>
</table>
</div>



## 1. ì „ì²˜ë¦¬


```python
X = df.iloc[:,:-1]
y = df['PRICE']

from sklearn.model_selection import train_test_split 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)
feature_names = X_test.columns.to_list()
```

## 2. Deep Explainer
Deep ExplainerëŠ” ë”¥ëŸ¬ë‹ ëª¨í˜•ì— íŠ¹í™”ëœ ì•Œê³ ë¦¬ì¦˜ì„ ì´ìš©í•˜ì—¬ SHAP valueë¥¼ ì¶”ì •í•œë‹¤. ì´ëŠ” ì…ë ¥ í…ì„œê°€ ì„œë¡œ ë…ë¦½ì´ë¼ê³  ê°€ì •í•˜ë©°, ë”¥ëŸ¬ë‹ ëª¨í˜•ì˜ ëª¨ë“  ì€ë‹‰ì¸µì´ ì…ë ¥ í…ì„œë¥¼ ì„ í˜•ê²°í•©ë§Œ í•œë‹¤ê³  ê°€ì •í•œë‹¤ëŠ” í•œê³„ê°€ ìˆë‹¤(í™œì„±í•¨ìˆ˜ì— ì˜í•œ ë¹„ì„ í˜•ê²°í•©ì„ ê³ ë ¤í•˜ì§€ ëª»í•œë‹¤). 

DeepExplainerë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë¨¼ì € ê°„ë‹¨í•œ ë”¥ëŸ¬ë‹ ëª¨í˜•ì„ ë§Œë“ ë‹¤. ì´ ëª¨í˜•ìœ¼ë¡œ DeepExplainer, GradientExplainerì˜ SHAP valueë¥¼ ê°ê° êµ¬í•  ì˜ˆì •ì´ë‹¤. 



```python
import tensorflow as tf
from tensorflow.keras import layers, models

input_shape = X_train.shape[1:]

inputs = tf.keras.Input(shape=input_shape)
x = layers.Dense(64, activation='relu')(inputs)
x = layers.Dense(32, activation='relu')(x)
outputs = layers.Dense(1)(x)

model_dl = models.Model(inputs=inputs, outputs=outputs)
model_dl.compile(optimizer='adam', loss='mse', metrics=['mae'])

model_dl.summary()
```


<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "functional_4"</span>
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ<span style="font-weight: bold"> Layer (type)                    </span>â”ƒ<span style="font-weight: bold"> Output Shape           </span>â”ƒ<span style="font-weight: bold">       Param # </span>â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">InputLayer</span>)      â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>)             â”‚             <span style="color: #00af00; text-decoration-color: #00af00">0</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">64</span>)             â”‚           <span style="color: #00af00; text-decoration-color: #00af00">896</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">32</span>)             â”‚         <span style="color: #00af00; text-decoration-color: #00af00">2,080</span> â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                â”‚ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)              â”‚            <span style="color: #00af00; text-decoration-color: #00af00">33</span> â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">3,009</span> (11.75 KB)
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">3,009</span> (11.75 KB)
</pre>




<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">0</span> (0.00 B)
</pre>



ëª¨í˜•ì˜ ì„±ëŠ¥ì„ íŒë‹¨í•˜ëŠ” metricì„ mean absolute errorë¡œ ì •ì˜í•˜ê³  ì‹œí—˜ë°ì´í„°ì…‹ì„ validation dataë¡œ ì§€ì •í•´ ì†ì‹¤í•¨ìˆ˜ê°’ê³¼ MAEë¥¼ êµ¬í•œë‹¤. mae=5.2746ìœ¼ë¡œ, ì•½ê°„ ê³¼ëŒ€ì í•©ì´ ì¼ì–´ë‚¬ë‹¤. 


```python
model_dl.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=30)
```

    Epoch 1/30
    [1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step - loss: 2051.5322 - mae: 36.6595 - val_loss: 253.1929 - val_mae: 14.0662
    ...
    Epoch 30/30
    [1m23/23[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 907us/step - loss: 36.6940 - mae: 4.5424 - val_loss: 37.8127 - val_mae: 5.0780





    <keras.src.callbacks.history.History at 0x33a6c2490>



í•œí¸ ì•ì„œ Kernel Expalinerë¥¼ ì ìš©í•  ë•Œ ìƒì„±í•œ ì„ í˜•íšŒê·€(LinearRegression) ëª¨í˜•ê³¼ ë”¥ëŸ¬ë‹ ëª¨í˜•ì˜ MAEë¥¼ ë¹„êµí•˜ë©´, ì„ í˜•íšŒê·€ ëª¨í˜•ë³´ë‹¤(MAE=3.163) ì„±ëŠ¥ì´ ë‚®ìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë”¥ëŸ¬ë‹ ëª¨í˜•ì— ì€ë‹‰ì¸µì„ ì¶”ê°€í•˜ê³  Dropout ì¸µì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ì„±ëŠ¥ì„ ê°œì„ í•˜ê³  ê³¼ëŒ€ì í•©ì„ ì™„í™”í•  ìˆ˜ ìˆì„ í…Œì§€ë§Œ ì´ ê³¼ì œì—ì„œëŠ” ìš°ì„  DeepExplainer ì ìš©ìœ¼ë¡œ ë„˜ì–´ê°€ê¸°ë¡œ í•œë‹¤.


```python
from sklearn.metrics import mean_absolute_error
y_pred_linear = model_linear.predict(X_test_std)
mae_linear = mean_absolute_error(y_test, y_pred_linear)
print("MAE of linear regression model: ", mae_linear)
```

    MAE of linear regression model:  3.1627098714574053


## 2.1 Deep Explainer: Global

ì•„ë˜ í”„ë¡œê·¸ë¨ì€ Deep Explainerë¥¼ êµ¬í•  background ë°ì´í„°ë¡œ X_trainì—ì„œ ëœë¤í•˜ê²Œ ë½‘ì€ 100ê°œì˜ í‘œë³¸ì„ ì§€ì •í•œë‹¤. í•œí¸, ë”¥ëŸ¬ë‹ ëª¨í˜•ìœ¼ë¡œë¶€í„° êµ¬í•œ SHAP valueì˜ shapeì€ (í‘œë³¸ìˆ˜, íŠ¹ì„±ë³€ìˆ˜ ìˆ˜, ì˜ˆì¸¡í•¨ìˆ˜ì˜ ì¶œë ¥ dimension)ì´ë‹¤. ê·¸ëŸ°ë° ì´ ë”¥ëŸ¬ë‹ ëª¨í˜•ì´ íšŒê·€ ëª¨í˜•ì´ë¯€ë¡œ ì¶œë ¥ dimension(ë§ˆì§€ë§‰ MLPì¸µì˜ ë…¸ë“œ ìˆ˜)ì€ 1ì´ë‹¤. ì¦‰ SHAP valueì˜ shapeì´ (152, 13, 1)ë¡œ ì£¼ì–´ì¡Œìœ¼ë¯€ë¡œ (152, 13)ìœ¼ë¡œ reshape í•´ì•¼ í•œë‹¤. 


```python
X_train = X_train.to_numpy()
background = X_train[np.random.choice(X_train.shape[0], 100, replace=False)]
```


```python
explainer_deep = shap.DeepExplainer(model=model_dl, data=background)
shap_values_deep = explainer_deep.shap_values(X_test.to_numpy())
print(shap_values_deep.shape)
# (152, 13, 1) í‘œë³¸ ìˆ˜, íŠ¹ì„±ë³€ìˆ˜ ìˆ˜, ë”¥ëŸ¬ë‹ ëª¨í˜•ì—ì„œ ë§ˆì§€ë§‰ MLPì¸µì˜ ë…¸ë“œ ìˆ˜

shap_values_deep = shap_values_deep.reshape(152, -1)
print(shap_values_deep.shape)
```

    (152, 13, 1)
    (152, 13)


    /opt/miniconda3/envs/env_xai_pthn39/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:99: UserWarning: Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.
      warnings.warn("Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.")



```python
shap.summary_plot(shap_values_deep, features=X_test, feature_names=feature_names, max_display=10)
```


    
![png](/images/m4/a4_2_deepGradientExplainer/output_17_0.png)
    


## 2.2 Deep Explainer: Local

ë‹¤ìŒì€ í‘œë³¸ í•˜ë‚˜ì˜ force plotìœ¼ë¡œ, Local Explainerì— í•´ë‹¹í•œë‹¤. ê¸°ëŒ“ê°’(í‰ê· )ì€ 24.61ì´ê³  LSTAT, B, INDUS ë³€ìˆ˜ê°€ ì£¼íƒê°€ê²© ì˜ˆì¸¡ì¹˜ë¥¼ ìƒìŠ¹ì‹œí‚¤ëŠ” ë°ì— ì¤‘ìš”í•œ ê¸°ì—¬ë¥¼ í•˜ê³  ìˆë‹¤. ì˜ˆì¸¡ì¹˜ í•˜ë½ì—ëŠ” ZN, TAX ë³€ìˆ˜ê°€ ì£¼ìš”í•˜ê²Œ ì‘ìš©í•˜ì˜€ë‹¤. ì˜ˆì¸¡ì¹˜ë¥¼ ìƒìŠ¹/í•˜ë½ì‹œí‚¤ëŠ” ìš”ì¸ì„ ì¢…í•©í•˜ì˜€ì„ ë•Œ, ì´ í‘œë³¸ì˜ ì£¼íƒê°€ê²© ì˜ˆì¸¡ì¹˜ëŠ” 29.13ì´ë‹¤. 


```python
expected_deep = explainer_deep.expected_value.numpy()

idx = 0

print(expected_deep)
print(shap_values_deep.shape)

shap.force_plot(expected_deep[0], shap_values_deep[idx], features=X_test.iloc[0, :])
```

    [24.608]
    (152, 13)



![png](/images/m4/a4_2_deepGradientExplainer/deep_2_2.png)





## 3. Gradient Explainer

Gradient ExplainerëŠ” Integrated Gradientsê°€ í™•ì¥ëœ Expected Gradientsë¥¼ ì‚¬ìš©í•´ ëª¨í˜•ì„ ì„¤ëª…í•œë‹¤. IGëŠ” í•˜ë‚˜ì˜ baselineì—ì„œ íŠ¹ì„±ë³€ìˆ˜ê°’ê¹Œì§€ì˜ êµ¬ê°„ì„ ë“±ë¶„í•˜ì—¬ ê° pointì—ì„œ êµ¬í•œ ë¯¸ë¶„ê°’(gradient)ì„ ì ë¶„í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë¹„ì„ í˜• í™œì„±í•¨ìˆ˜ì— ì˜í•œ ê¸°ì—¬ë„ ì™œê³¡ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. ê·¸ë ‡ì§€ë§Œ IGëŠ” ì—„ë°€íˆëŠ” SHAP valueê°€ ì•„ë‹ˆë‹¤. IGê°€ SHAP valueë¥¼ ê·¼ì‚¬í•˜ë„ë¡ ìˆ˜ì •í•œ ê²ƒì´ Expected Gradientsì´ë‹¤. Expected GradientsëŠ” background dataì—ì„œ ìƒ˜í”Œë§í•œ ì—¬ëŸ¬ ê¸°ì¤€ê°’ì„ ì ìš©í•˜ê³ , ê° ê¸°ì¤€ê°’(baseline)ì—ì„œì˜ IGë¥¼ ê³„ì‚°í•˜ì—¬ ê·¸ ê°’ë“¤ì˜ í‰ê· ìœ¼ë¡œ êµ¬í•œë‹¤. ë”¥ëŸ¬ë‹ ëª¨í˜•ì—ì„œ í™œì„±í•¨ìˆ˜ì— ì˜í•œ ë¹„ì„ í˜• ê²°í•©ì„ ê³ ë ¤í•˜ì§€ ëª»í•˜ëŠ” Deep Explainerì™€ ë‹¬ë¦¬ Gradient ExplainerëŠ” ëª¨í˜•ì— ë¹„ì„ í˜• ê²°í•©ì´ ìˆì–´ë„ ê¸°ì—¬ë„ì˜ ì™œê³¡ ì—†ì´ SHAP valueë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë‘ Explainerë¥¼ í•¨ê»˜ ì‚´í´ë´ì•¼ í•œë‹¤. 


```python
explainer_ge = shap.GradientExplainer(model_dl, background)

shap_values_ge = explainer_ge.shap_values(X_test.to_numpy())
print(shap_values_ge.shape)
# (152, 13, 1) í‘œë³¸ ìˆ˜, íŠ¹ì„±ë³€ìˆ˜ ìˆ˜, ë”¥ëŸ¬ë‹ ëª¨í˜•ì—ì„œ ë§ˆì§€ë§‰ MLPì¸µì˜ ë…¸ë“œ ìˆ˜

shap_values_ge = shap_values_ge.reshape(152, -1)
print(shap_values_ge.shape)
```

    (152, 13, 1)
    (152, 13)


DeepExplainerë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ í‘œë³¸(X_testì˜ ì¸ë±ìŠ¤ 0)ì˜ local explainerë¥¼ êµ¬í˜„í•œ ê²ƒì²˜ëŸ¼, GradientExplainerë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ í‘œë³¸ì˜ explainerë¥¼ êµ¬í˜„í•˜ê³  ì‹œê°í™” í•˜ì˜€ë‹¤. GradientExplainer ê°ì²´ì—ëŠ” expected_valueë¥¼ êµ¬í•˜ëŠ” ì†ì„±ì´ ì—†ê¸° ë•Œë¬¸ì— ë³„ë„ë¡œ ê³„ì‚°í•´ì•¼ í•œë‹¤.

Deep Explainerì™€ Gradient Explainerë¡œ êµ¬í•œ ê¸°ëŒ“ê°’ê³¼ SHAP valueë¥¼ ë¹„êµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. 
- DeepExplainerë¡œ êµ¬í•œ ê¸°ëŒ“ê°’(24.61)ê³¼ GradientExplainerë¡œ êµ¬í•œ ê¸°ëŒ“ê°’(24.23)ì— ì•½ê°„ ì°¨ì´ê°€ ìˆë‹¤. 
- DeepExplainerë¡œ êµ¬í•œ SHAP valueì˜ ê²½ìš° íŠ¹ì„±ë³€ìˆ˜ ZNì˜ í•˜ë°© ì˜í–¥ì´, GradientExplainerë¡œ êµ¬í•œ SHAP valueì˜ ê²½ìš° íŠ¹ì„±ë³€ìˆ˜ TAXì˜ í•˜ë°© ì˜í–¥ì´ ì¢€ë” í¬ê²Œ ë‚˜íƒ€ë‚¬ì§€ë§Œ ì „ë°˜ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆë‹¤.



```python
expected_ge = model_dl.predict(X_train).mean()
print(expected_ge)

idx = 0

print(shap_values_ge.shape)

shap.force_plot(expected_ge, shap_values_ge[idx], features=X_test.iloc[0, :])
```

    [1m12/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 584us/step
    24.225084
    (152, 13)



![png](/images/m4/a4_2_deepGradientExplainer/deep_3.png)


