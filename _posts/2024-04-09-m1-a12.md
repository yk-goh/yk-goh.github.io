---
layout: single
title: "Clustering algorithms: K-means++, DBSCAN and HDBSCAN"
categories: ML
sidebar: true
use_math: true
---
# 문제: sklearn에서 제공하는 make_circles data에 적절한 noise를 첨가한 후, K-means++, DBSCAN, HDBSCAN을 적용하여 비교하라


```python
from sklearn.datasets import make_circles
import plotly.express as px

X, y = make_circles(n_samples=200, noise=.08, random_state=0, factor=.4)
fig = px.scatter(x=X[:, 0], y=X[:, 1])
fig.update_layout(width=500, height=380)
fig.show()
```

![png](/images/m1/a12/newplot1.png)


make_circles() 함수를 이용해 noise=.08, factor=.4로 지정하여 원을 만든다. 시각적으로 두 개의 군집을 확인할 수 있다. 

## 1) K-means++
K-means++ 클러스터링을 실행하기 위해서는 클러스터의 개수를 지정해야 하므로 일반적으로 elbow plot을 그려 적절한 군집의 수를 확인하나, 지금은 군집의 수가 2개임을 알고 있으므로 n_clusters=2로 지정하여 scatter plot을 그린다. K-means++은 공간을 직선으로 나누는 선형적 군집화 알고리즘이므로 이 데이터처럼 곡면형일 때 K-means++은 성능이 좋지 않다.



```python
from sklearn.cluster import KMeans

distortions = []

for i in range(1, 11):
    km = KMeans(n_clusters=i, n_init=10, max_iter=300, random_state=0)
    km.fit(X)
    distortions.append(km.inertia_)

import numpy as np
import plotly.graph_objects as go

fig = go.Figure()
fig.add_trace(go.Scatter(x=np.arange(1,11), y=distortions, mode='lines+markers'))
fig.update_layout(width=500, height=400)
fig.update_xaxes(title_text='number of clusters')
fig.update_yaxes(title_text='SSE(k)')
fig.show()
```

![png](/images/m1/a12/newplot2.png)




```python
km = KMeans(n_clusters=2, init='k-means++')
y_km = km.fit_predict(X)

fig = go.Figure()
fig.add_trace(go.Scatter(x = X[y_km==0, 0], y = X[y_km==0, 1], mode = 'markers', name='cluster1'))
fig.add_trace(go.Scatter(x = X[y_km==1, 0], y = X[y_km==1, 1], mode = 'markers', name='cluster2'))
fig.add_trace(go.Scatter(x = X[y_km==2, 0], y = X[y_km==2, 1], mode = 'markers', name='cluster3'))
fig.update_layout(width=500, height=380)
```

    /Users/ykgoh/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:
    
    The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
    

![png](/images/m1/a12/newplot3.png)



K-means++은 공간을 선분으로 나누는 선형적 군집이다. 위 데이터처럼 곡면형일 때 K-means++ 군집은 성능이 좋지 않다

## 2) DBSCAN
DBSCAN은 공간 상에 높은 밀도로 모여 있는 관측치를 하나의 그룹으로 간주하고, 낮은 밀도를 가지고 홀로 있는 관측치는 이상치(noise)로 분류하는 알고리즘이다. min_sample 파라미터는 기본값(5)으로 고정하고 eps(epsilon-nearest neighbors)를 변경하며 cluster detection 결과를 시각화 하였다.
 -	epsilon이 작을 때(eps=.1, eps=.2) 국지적으로 밀도 높게 모여 있는 점들이 하나의 군집으로 분류되었다.
 -	eps=.3 이상일 때 DBSCAN은 하나의 군집을 찾는다.
 
eps 파라미터가 뜻하는 epsilon은 관측치가 군집을 찾기 위한 영역의 반지름이라고 이해할 수 있으므로 eps를 너무 작게 지정하면 전반적인 군집 구조를 파악하기 어렵다.



```python
from sklearn.cluster import DBSCAN
from plotly.subplots import make_subplots

fig = make_subplots(rows=1, cols=5, subplot_titles=('eps=.1', 'eps=.2', 'eps=.3', 'eps=.4', 'eps=.5'))
epsilons = np.linspace(.1, .5, 5) # 총 5개

for eps, i in zip(epsilons, range(1,6)): 
    db = DBSCAN(eps=eps, min_samples=5, metric='euclidean')
    y_db = db.fit_predict(X)
    clusters = np.unique(y_db)
    for cluster , c in zip(clusters, range(0, len(clusters))):
        fig.add_trace(go.Scatter(x = X[y_db==cluster, 0], y = X[y_db==cluster, 1], mode = 'markers', 
                                 name='cluster{}'.format(c+1)), row=1, col=i)

fig.update_layout(width=1200, height=350)
fig.show()
```

![png](/images/m1/a12/newplot4.png)



## 3) HDBSCAN


```python
!pip install hdbscan
import hdbscan
```




```python
fig = make_subplots(rows=1, cols=5, subplot_titles=('M=10','M=15', 'M=20', 'M=25', 'M=30'))
M_list = [10, 15, 20, 25, 30]

for M, i in zip(M_list, range(1,6)): 
    hdb = hdbscan.HDBSCAN(min_samples=M)
    y_hdb = hdb.fit_predict(X)

    clusters = np.unique(y_hdb)
    for cluster , c in zip(clusters, range(0, len(clusters))):
        fig.add_trace(go.Scatter(x = X[y_hdb==cluster, 0], y = X[y_hdb==cluster, 1], mode = 'markers', 
                                 name='cluster{}'.format(c+1)), row=1, col=i)

fig.update_layout(width=1200, height=350)
fig.show()
```
![png](/images/m1/a12/newplot5.png)



DBSCAN은 군집을 형성하기 위한 최소 관측치 개수(M)와 e-nearest neighbors를 기반으로 군집을 찾아낸다. 그런데 epsilon은 너무 작으면 많은 관측치가 noise로 분류되고, epsilon이 너무 크면 군집의 개수가 너무 작아진다. 이러한 초모수 epsilon을 결정해야 하는 문제를 해결하는 군집기법이 HDBSCAN이다. 

큰 epsilon에서 시작하여(하나의 군집만 존재) 점차적으로 epsilon을 감소시키면서 기존 군집에서 관측치가 떨어져 나가고, 자식 군집이 생성되는 방식이다. epsilon을 계속 감소시키며 군집의 크기가 최소 M이 될 때까지 계속한다. 이 때, 안정성(stability)을 계산하여 자식군집의 안정성 합이 부모군집의 안정성 합보다 작다면 자식군집을 참군집에서 제외한다.

HDBSCAN에서 초모수는 M이다. M은 군집의 최소 크기이기도 하고, 상호접근가능거리(mutually reachable distance)를 계산하는데 사용되기도 한다. M이 클수록 밀집된 군집 내 관측치(xp)와 이상치인(홀로 떨어진) 점(xq)의 mrd도 유클리디안 거리로 일정해진다. 

위 그림에서도 M(HDBSCAN()의 min_samples 파라미터)이 클수록 주어진 데이터를 하나의 군집으로 찾아내고 있음을 확인할 수 있다.


```python
hdb.condensed_tree_.plot(select_clusters=True)
```




    
![png](/images/m1/a12/output_13_1.png)
    


