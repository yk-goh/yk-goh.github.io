---
layout: post
title:  "Monte Carlo 추론"
categories: 통계적 머신러닝
---

# Monte Carlo 추론 예제

(1) 3개의 각기 다른 표본에서의 추정치와 추정치의 분산을 비교할 것.

(2) 반복을 1000번하여 95% confidence interval을 제시할 것

(3) (1)번에 대응하여 MonteCarlo 추론(모수 예측과 confidence interval) 결과를 제시하고 그 결과를 (1)과 비교할 것.

## 0. 함수 정의 및 표본 생성
generate_logistic() 함수를

(1) -5.0부터 5.0까지 0.2 간격으로 생성한 50개의 x와

(2) (1)에서 생성한 x에 $a+bx+cx^2$(a=1, b=2, c=3) 을 취한 뒤 α=2, β=5인 베타분포를 따르는 랜덤한 값\*18을 더하여 생성한 50개의 y를 리턴하는 함수로 정의하고, 세 번 실행하여 각각 sample1, sample2, sample3로 명명한다. sample1~3의 x, y에 비선형 최소제곱법으로 모델을 적합하는 curve_fit() 함수를 적용하고, 모델함수 인자로 y를 생성하는 데 사용한 2차 다항식 (1+2\*x+3\*x^2)을 넘긴다.



```python
# general libraries
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
```


```python
def func_2(p, a, b, c): 
  """
  Two-degree polynomial.2차함수(다항식)
  """
  return a + b*p + c*p**2
```


```python
# 숙제!
# size=0.2로 수정: 표본크기를 50으로 하기 위해 

def generate_logistic(size=0.2):
    x = np.arange(-5.0, 5.0, size, dtype = np.float64) 
    y = func_2(x, 1, 2, 3) + 18.0 * np.random.beta(2,5, size = len(x))
    print(len(x))
    return x,y
```


```python
x,y=generate_logistic()
x1,y1 = generate_logistic()
x2,y2 = generate_logistic()
```

    50
    50
    50



```python
fig = plt.figure()
ax = fig.add_subplot(111) # 1행 1열의 첫 번째라는 뜻. (1,1,1)로 작성해도 됨
# plt.figure.add_subplot()은 axes.Axes 객체를 반환한다.
# Axes는 플롯의 이미지, 축의 메모리, 레이블 설정 등을 담당한다.

ax.scatter(x, y, color = 'violet', linewidths = 2)

plt.ylabel('y')
plt.xlabel('x')

plt.ylim(-50, 110)
plt.xlim(-6, 6)

plt.axis(True)
plt.show()
```


    
![png](/images/m1/a1/output_6_0.png)
    


#### curve_fit(모델함수, x, y)
- 모델함수: 데이터를 추정하기 위한 함수의 기본형
- return: popt, pcov
    - popt: 모델함수의 파라미터
    - pcov: popt의 공분산 추정값 (대각성분은 Cov(X,X) 즉 Var(X) 이다)


```python
# 선형모형 추정
popt, pcov = curve_fit(func_2, x, y)
popt1, pcov1 = curve_fit(func_2, x1, y1)
popt2, pcov2 = curve_fit(func_2, x2, y2)
# 추정하는 파라미터의 적정 범위를 알고 있다면 curve_fit()의 인자로 bounds=([a최소값, b최소값], [a최대값, b최대값])을 입력하여 
# 파라미터의 자유도를 제한함으로써 원하는 함수를 더 정확히 추정할 수 있다. 하지만 범위 설정이 잘못되면 원하는 결과를 얻지 못할 것임

```

## 1. 세 개의 각기 다른 표본에서 추정치와 추정치의 분산을 비교하기
### 1) a, b, c 추정치
curve_fit() 함수가 반환하는 popt는 잔차제곱합이 최소가 되는 최적의 모수 즉 a, b, c의 추정치를 알려주며 sample1~3에 대하여 다음과 같다(리스트의 왼쪽부터 a, b, c 순서).


```python

print('sample1:', popt) # 실행할 때마다 바뀐다 
print('sample2:', popt1)
print('sample3:', popt2)
```

    sample1: [6.24388813 1.87648732 2.99438957]
    sample2: [6.41926863 2.20131134 2.97918476]
    sample3: [6.20433111 2.03120348 3.01950174]


### 2) a, b, c 추정치의 분산
pcov의 대각성분은 각 파라미터의 variance이다. curve_fit() 함수가 반환하는 pcov의 대각성분으로부터 얻을 수 있는 a, b, c 추정치의 분산은 다음과 같다(리스트의 왼쪽부터 a, b, c 순서).
- 파라미터의 uncertainties를 pcov로부터 확인하기
    - 행렬 대각화: np.diag(pcov)


```python
print(pcov)

# 실행할 때마다 아래 값이 변경됨을 확인 
# 수리통계학의 통계적 추론이 복불복이라는 것.
```

    [[ 0.40799964 -0.00326574 -0.02721449]
     [-0.00326574  0.02190243  0.00065419]
     [-0.02721449  0.00065419  0.00327097]]



```python
perr = np.diag(pcov)
perr1 = np.diag(pcov1)
perr2 = np.diag(pcov2)
print("sample1:", perr)
print("sample2:", perr1)
print("sample3:", perr2)
# curve_fit()의 bounds 인자의 값을 변경할 때 perr값을 참고하며 perr이 작아지도록 bounds를 조정한다 
```

    sample1: [0.40799964 0.02190243 0.00327097]
    sample2: [0.4741755  0.02545492 0.00380151]
    sample3: [0.40791261 0.02189776 0.00327027]



```python
fig = plt.figure()
ax = fig.add_subplot(111)

ax.scatter(x, y, color = 'violet', linewidths = 2)
ax.plot(x, func_2(x, *popt), lw = 3, color = 'lime')

plt.ylabel('y')
plt.xlabel('x')

plt.ylim(-50, 110)
plt.xlim(-6, 6)

plt.axis(True)
plt.show()
```


    
![png](/images/m1/a1/output_14_0.png)
    


## 2. 1000회 반복하여 95% CI 구하기


```python
import pandas as pd

# 기본값: 100회 추출
def dist_est(x,repeat=100, sigma=18.0):
    y_2 = []
    popt_l = []
    for i in range (0, repeat):
        # 재현을 위해 seed 설정
        np.random.seed(seed = i)
        # beta분포로 변경
        y_2.append(func_2(x, 1, 2, 3) + sigma * np.random.beta(2, 5, size = len(x)))
        popt, _ = curve_fit(func_2, x, y_2[i])
        popt_l.append(popt)
    est_params=pd.DataFrame(popt_l, columns=['a','b','c'])
    print(f'repeat={repeat}',f'sigma={sigma}')
    print(est_params.describe())
    print('====================95% confidence interval=====================')
    print(est_params.quantile(q=0.025))
    print(est_params.quantile(q=0.975))

```

### repeat = 1000, sigma = 18.0
1.번과 동일한 분포에서 Sample size가 50인 표본을 추출하는 과정을 1000회 반복한다. 총 1000개의 표본에 각각 2차 다항식 모델함수를 적합하여 모수 a, b, c의 추정치의 95%가 포함된 구간을 구하면 다음과 같다.


```python
dist_est(x,repeat=1000) # a의 표준편차 = 0.584632 
```

    repeat=1000 sigma=18.0
                     a            b            c
    count  1000.000000  1000.000000  1000.000000
    mean      6.131763     2.008358     3.000804
    std       0.584632     0.144138     0.054408
    min       4.346979     1.480477     2.805282
    25%       5.737318     1.911272     2.964398
    50%       6.145950     2.004442     3.001115
    75%       6.514532     2.104732     3.034041
    max       8.120159     2.555677     3.187466
    ====================95% confidence interval=====================
    a    5.015707
    b    1.728524
    c    2.899601
    Name: 0.025, dtype: float64
    a    7.245094
    b    2.295969
    c    3.110235
    Name: 0.975, dtype: float64


이로부터 다음 두 가지를 확인할 수 있다.
-	1.번에서 생성한 표본 중 sample1의 경우 a의 95% 신뢰구간(5.02, 7.25)에서 벗어난 값(7.45)을 모수 a의 값으로 추정하였음을 확인할 수 있다.
-	모수 a, b, c의 추정치인 mean을 살펴보면 각각 참값인 6.14 , 2, 3과 가깝다.
그러나 현실 세계에서 표본의 개수는 제한적이므로 표본크기가 50인 표본을 1000개 생성할 수 없다. 이러한 제약을 타개하기 위해 Monte Carlo추론 방법이 사용된다. 



```python
print(0.584632**2)
print(0.144138**2)
print(0.054408**2)
```

    0.34179457542400005
    0.020775763043999997
    0.0029602304639999998


## 3. (1)번에 대응하여 MonteCarlo 추론(모수 예측과 confidence interval) 결과를 제시하고 그 결과를 (1)과 비교할 것.


```python
# 상단에서 사용한 x y 페어를 다시 사용한다

xx = pd.DataFrame(x,columns=['x'])
yyy = pd.DataFrame(y,columns=['y'])
data = pd.merge(xx,yyy,left_index=True,right_index=True)

xx1 = pd.DataFrame(x1,columns=['x'])
yyy1 = pd.DataFrame(y1,columns=['y'])
data1 = pd.merge(xx1,yyy1,left_index=True,right_index=True)

xx2 = pd.DataFrame(x2,columns=['x'])
yyy2 = pd.DataFrame(y2,columns=['y'])
data2 = pd.merge(xx2,yyy2,left_index=True,right_index=True)

print(data.shape)
print(data1.shape)
print(data2.shape)
```

    (50, 2)
    (50, 2)
    (50, 2)



```python
def resample_est(n_iter=1000, frac=1, data=data):
    pop_sample=[]
    for _ in range(n_iter):
        resample=data.sample(frac=frac,replace=True)
        # frac: 전체 표본수 대비 추출 비율
        popt, _ = curve_fit(func_2, resample['x'], resample['y'])
        pop_sample.append(popt)
    est_params=pd.DataFrame(pop_sample, columns=['a','b','c'])
    print(f'n_iter={n_iter}',f'sample size={len(data)}',f'fraction={frac}')
    print(est_params.describe())
    print('==========95% confidence interval===========') # a, b, c의 95% 신뢰구간
    print(est_params.quantile(q=0.025))
    print(est_params.quantile(q=0.975))

```

### 3.1 data(50,2)에서 추출, 1000회 반복, 표본 크기는 50


```python
resample_est(data=data)
```

    n_iter=1000 sample size=50 fraction=1
                     a            b            c
    count  1000.000000  1000.000000  1000.000000
    mean      6.268230     1.880330     2.991225
    std       0.694785     0.136398     0.058920
    min       4.050532     1.335228     2.810251
    25%       5.780437     1.790273     2.952141
    50%       6.242837     1.877663     2.989964
    75%       6.750753     1.977678     3.031435
    max       8.779713     2.424223     3.203100
    ==========95% confidence interval===========
    a    4.914687
    b    1.603313
    c    2.881390
    Name: 0.025, dtype: float64
    a    7.658831
    b    2.132690
    c    3.102350
    Name: 0.975, dtype: float64


### 3.2 data1에서 추출, 1000회 반복, 표본 크기는 50


```python
resample_est(data = data1)
```

    n_iter=1000 sample size=50 fraction=1
                     a            b            c
    count  1000.000000  1000.000000  1000.000000
    mean      6.443842     2.198570     2.978648
    std       0.672906     0.162834     0.060179
    min       4.082772     1.567063     2.774335
    25%       5.986616     2.096768     2.938635
    50%       6.451691     2.206012     2.980133
    75%       6.915689     2.302971     3.020025
    max       8.264019     2.723859     3.224712
    ==========95% confidence interval===========
    a    5.185149
    b    1.866934
    c    2.865507
    Name: 0.025, dtype: float64
    a    7.758013
    b    2.512951
    c    3.091355
    Name: 0.975, dtype: float64


### 3.2 data2에서 추출, 1000회 반복, 표본 크기는 50


```python
resample_est(data = data2)
```

    n_iter=1000 sample size=50 fraction=1
                     a            b            c
    count  1000.000000  1000.000000  1000.000000
    mean      6.203802     2.025950     3.017375
    std       0.677933     0.146565     0.060997
    min       4.227025     1.560430     2.796045
    25%       5.753975     1.931945     2.978212
    50%       6.198617     2.027804     3.020606
    75%       6.638395     2.120841     3.057746
    max       8.291952     2.463534     3.217477
    ==========95% confidence interval===========
    a    4.864582
    b    1.740974
    c    2.894856
    Name: 0.025, dtype: float64
    a    7.559762
    b    2.315390
    c    3.136862
    Name: 0.975, dtype: float64


sample1, 2, 3에서 각각 sample size를 50으로 하는 복원반복추출을 1000회 시행하였다(bootstrapping). 
Monte Carlo 추론을 이용한 경우, 모형으로부터 생성한 표본에서 바로 함수를 적합했을 때보다(그림 1) 모수 a의 추정치가 참값 6.14에 가깝게 나타나며 이는 sample 1~3에서 동일하게 관찰된다. 

